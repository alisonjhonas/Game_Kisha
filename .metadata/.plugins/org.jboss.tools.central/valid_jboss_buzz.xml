<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>How Quarkus brings imperative and reactive programming together</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qFbfp1AZQJ4/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="OpenJDK" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="reactive programming" scheme="searchisko:content:tags" /><author><name>Syed M Shaaf</name></author><id>searchisko:content:id:jbossorg_blog-how_quarkus_brings_imperative_and_reactive_programming_together</id><updated>2019-11-18T08:00:43Z</updated><published>2019-11-18T08:00:43Z</published><content type="html">&lt;p&gt;The supersonic subatomic Java singularity has expanded!&lt;/p&gt; &lt;p&gt;42 releases, 8 months of community participation, and 177 amazing contributors led up to the release of &lt;a href="https://developers.redhat.com/topics/quarkus/"&gt;Quarkus 1.0&lt;/a&gt;.  This release is a significant milestone with a lot of cool features behind it. You can read more in the &lt;a href="https://quarkus.io/blog/announcing-quarkus-1-0/"&gt;release announcement&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Building on that awesome news, we want to delve into how Quarkus unifies both imperative and reactive programming models and its reactive core. We&amp;#8217;ll start with a brief history and then take a deep dive into what makes up this dual-faceted reactive core and how &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; developers can take advantage of it.&lt;span id="more-653567"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices/"&gt;Microservices&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven architectures&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;serverless&lt;/a&gt; functions are on the rise. Creating a cloud-native architecture has become more accessible in the recent past; however, challenges remain, especially for Java developers. Serverless functions and microservices need faster startup times, consume less memory, and above all offer developer joy. Java, in that regard, has just in recent years done some improvements (e.g., ergonomics enhancements for containers, etc.). However, to have a performing container-native Java, it hasn&amp;#8217;t been easy. Let&amp;#8217;s first take a look at some of the inherent issues for developing container-native Java applications.&lt;/p&gt; &lt;p&gt;Let’s start with a bit of history.&lt;/p&gt; &lt;p&gt;&lt;img class=" wp-image-653597 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-05-at-01.04.16-1024x367.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-05-at-01.04.16-300x108.png" alt="Threads CPUs Java and Containers" width="892" height="321" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-05-at-01.04.16-300x108.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-05-at-01.04.16-768x275.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/Screenshot-2019-11-05-at-01.04.16-1024x367.png 1024w" sizes="(max-width: 892px) 100vw, 892px" /&gt;&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Threads and containers&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;As of version 8u131, Java is more container-aware, due to the ergonomics enhancements. So now, the JVM knows the number of cores it&amp;#8217;s running on and can customize thread pools accordingly — typically the fork/join pool. That&amp;#8217;s all great, but let&amp;#8217;s say we have a traditional web application that uses HTTP servlets or similar on Tomcat, Jetty, or the like. In effect, this application gives a thread to each request allowing it to block this thread when waiting for IO to occur, such as accessing databases, files, or other services. The sizing for such an application depends on the number of concurrent requests rather than the number of available cores; this also means quota or limits in Kubernetes on the number of cores will not be of great help and eventually will result in throttling.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Memory exhaustion&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Threads also cost memory. Memory constraints inside a container do not necessarily help. Spreading that over multiple applications and threading to a large extent will cause more switching and, in some cases, performance degradation. Also, if an application uses traditional microservices frameworks, creates database connections, uses caching, and perhaps needs some more memory, then straightaway one would also need to look into the JVM memory management so that it’s not getting killed (e.g., XX:+UseCGroupMemoryLimitForHeap). Even though JVM can understand cgroups as of Java 9 and adapt memory accordingly, it can still get quite complex to manage and size the memory.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Quotas and limits&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;With Java 11, we now have the support for CPU quotas (e.g., PreferContainerQuotaForCPUCount). Kubernetes also provides support for limits and quotas. This could make sense; however, if the application uses more than the quota again, we end up with sizing based on cores, which in the case of traditional Java applications, using one thread per request, is not helpful at all.&lt;/p&gt; &lt;p&gt;Also, if we were to use quotas and limits or the scale-out feature of the underlying Kubernetes platform, the problem wouldn&amp;#8217;t solve itself; we would be throwing more capacity at the underlying issue or end up over-committing resources. And if we were running this on a high load in a public cloud, certainly we would end up using more resources than necessary.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;What can solve this?&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;A straightforward solution to these problems would be to use asynchronous and non-blocking IO libraries and frameworks like Netty, &lt;a href="https://developers.redhat.com/blog/2019/10/21/eclipse-vert-x-3-8-1-update-for-red-hat-runtimes/"&gt;Vert.x,&lt;/a&gt; or Akka. They are more useful in containers due to their reactive nature. By embracing non-blocking IO, the same thread can handle multiple concurrent requests. While a request processing is waiting for some IO, the thread is released and so can be used to handle another request. When the IO response required by the first request is finally received, processing of the first request can continue. Interleaving request processing using the same thread reduces the number of threads drastically and also resources to handle the load.&lt;/p&gt; &lt;p&gt;With non-blocking IO, the number of cores becomes the essential setting as it defines the number of IO threads you can run in parallel. Used properly, it efficient dispatches the load on the different cores, handling more with fewer resources.&lt;/p&gt; &lt;h2&gt;Is that all?&lt;/h2&gt; &lt;p&gt;And, there&amp;#8217;s more. Reactive programming improves resource usage but does not come for free. It requires that the application code embrace non-blocking and avoid blocking the IO thread. This is a different development and execution model. Although there are many libraries to help you do this, it&amp;#8217;s still a mind-shift.&lt;/p&gt; &lt;p&gt;First, you need to learn how to write code executed asynchronously because, as soon as you start using non-blocking IOs, you need to express what is going to happen once the response is received. You cannot wait and block anymore. To do this, you can pass callbacks, use reactive programming, or continuation. But, that&amp;#8217;s not all, you need to use non-blocking IOs and so have access to non-blocking servers and clients for everything you need. HTTP is the simple case, but think about database access, file systems, and so on.&lt;/p&gt; &lt;p&gt;Although end-to-end reactive provides the best efficiency, the shift can be hard to comprehend. Having the ability to mix both reactive and imperative code is becoming essential to:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Use efficiently the resources on hot paths, and&lt;/li&gt; &lt;li&gt;Provide a simpler code style for the rest of the application.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Enter Quarkus&lt;/h2&gt; &lt;p&gt;This is what Quarkus is all about: unifying reactive and imperative in a single runtime.&lt;/p&gt; &lt;p&gt;Quarkus uses Vert.x and Netty at its core. And, it uses a bunch of reactive frameworks and extensions on top to help developers. Quarkus is not just for HTTP microservices, but also for event-driven architecture. Its reactive nature makes it very efficient when dealing with messages (e.g., Apache Kafka or AMQP).&lt;/p&gt; &lt;p&gt;The secret behind this is to use a single reactive engine for both imperative and reactive code.&lt;/p&gt; &lt;p&gt;&lt;img class=" wp-image-653607 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/reactive-quarkus-1024x489.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/reactive-quarkus-300x143.png" alt="" width="913" height="435" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/reactive-quarkus-300x143.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/reactive-quarkus-768x367.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/reactive-quarkus-1024x489.png 1024w" sizes="(max-width: 913px) 100vw, 913px" /&gt;&lt;/p&gt; &lt;p&gt;Quarkus does this quite brilliantly. Between imperative and reactive, the obvious choice is to have a reactive core. What that helps with is a fast non-blocking code that handles almost everything going via the event-loop thread (IO thread). But, if you were creating a typical REST application or a client-side application, Quarkus also gives you the imperative programming model. For example, Quarkus HTTP support is based on a non-blocking and reactive engine (Eclipse Vert.x and Netty). All the HTTP requests your application receive are handled by &lt;i&gt;event loops&lt;/i&gt; (IO Thread) and then are routed towards the code that manages the request. Depending on the destination, it can invoke the code managing the request on a worker thread (servlet, Jax-RS) or use the IO was thread (reactive route).&lt;/p&gt; &lt;p id="ObTUmeC"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d.png"&gt;&lt;img class=" wp-image-653617 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d.png 771w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d-300x137.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcca0ed0a68d-768x352.png 768w" sizes="(max-width: 771px) 100vw, 771px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For messaging connectors, non-blocking clients are used and run on top of the Vert.x engine. So, you can efficiently send, receive, and process messages from various messaging middleware.&lt;/p&gt; &lt;p&gt;To help you get started with reactive on Quarkus, there are some well-articulated guides on &lt;a href="http://www.quarkus.io"&gt;Quarkus.io:&lt;/a&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/reactive-routes-guide"&gt;Using Reactive Routes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/reactive-sql-clients"&gt;Reactive SQL Clients&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/kafka-guide"&gt;Using Apache Kafka with Reactive Messaging&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/amqp-guide"&gt;Using AMQP with Reactive Messaging&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/using-vertx"&gt;Using Vertx API&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;There are also reactive demo scenarios that you can try online; you don&amp;#8217;t need a computer or an IDE, just give it a go in your browser. You can try them out &lt;a href="https://learn.openshift.com/middleware/courses/middleware-quarkus/"&gt;here.&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Additional resources&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/cms/managed-files/cl-4-reasons-try-quarkus-checklist-f19180cs-201909-en.pdf"&gt;Four reasons to try Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quarkus website:&lt;a href="http://quarkus.io"&gt; http://quarkus.io&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quarkus GitHub project:&lt;a href="https://github.com/quarkusio/quarkus"&gt; https://github.com/quarkusio/quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quarkus Twitter:&lt;a href="https://twitter.com/QuarkusIO"&gt; https://twitter.com/QuarkusIO&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quarkus chat:&lt;a href="https://quarkusio.zulipchat.com/"&gt; https://quarkusio.zulipchat.com/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Quarkus mailing list:&lt;a href="https://groups.google.com/forum/#!forum/quarkus-dev"&gt; https://groups.google.com/forum/#!forum/quarkus-dev&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#38;linkname=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fhow-quarkus-brings-imperative-and-reactive-programming-together%2F&amp;#038;title=How%20Quarkus%20brings%20imperative%20and%20reactive%20programming%20together" data-a2a-url="https://developers.redhat.com/blog/2019/11/18/how-quarkus-brings-imperative-and-reactive-programming-together/" data-a2a-title="How Quarkus brings imperative and reactive programming together"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/18/how-quarkus-brings-imperative-and-reactive-programming-together/"&gt;How Quarkus brings imperative and reactive programming together&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qFbfp1AZQJ4" height="1" width="1" alt=""/&gt;</content><summary>The supersonic subatomic Java singularity has expanded! 42 releases, 8 months of community participation, and 177 amazing contributors led up to the release of Quarkus 1.0.  This release is a significant milestone with a lot of cool features behind it. You can read more in the release announcement. Building on that awesome news, we want to delve into how Quarkus unifies both imperative and reactiv...</summary><dc:creator>Syed M Shaaf</dc:creator><dc:date>2019-11-18T08:00:43Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/18/how-quarkus-brings-imperative-and-reactive-programming-together/</feedburner:origLink></entry><entry><title>New tools for automating end-to-end tests for VS Code extensions</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/k8n_JCKObGY/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="test automation" scheme="searchisko:content:tags" /><category term="VS Code" scheme="searchisko:content:tags" /><category term="VS Code Extensions" scheme="searchisko:content:tags" /><author><name>Jan Richter</name></author><id>searchisko:content:id:jbossorg_blog-new_tools_for_automating_end_to_end_tests_for_vs_code_extensions</id><updated>2019-11-18T08:00:19Z</updated><published>2019-11-18T08:00:19Z</published><content type="html">&lt;p&gt;It is a common practice to test software from the user&amp;#8217;s perspective before releasing it. With this assumption, I have set out on a quest to find a &lt;a href="https://developers.redhat.com/blog/category/vs-code/"&gt;VS Code&lt;/a&gt; extension with automated end-to-end tests. My quest ended in failure. Naturally, a lazy person like me then asked: &amp;#8220;Why would nobody try to automate this?&amp;#8221; It turns out that automating this was, in fact, quite difficult.&lt;/p&gt; &lt;p&gt;My quest then became finding a solution that would enable developers to do just the thing. It is my pleasure to announce that no more hours need be wasted on this menial, manual activity. Enter the aptly named &lt;a href="https://www.npmjs.com/package/vscode-extension-tester" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;vscode-extension-tester&lt;/code&gt;&lt;/a&gt;: A framework that lets you create automated tests for your VS Code extensions and launch them with ease. All you need is an &lt;a href="https://www.npmjs.com/package/vscode-extension-tester" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;npm&lt;/code&gt; package&lt;/a&gt;.&lt;span id="more-646517"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;How it works&lt;/h2&gt; &lt;p&gt;VS Code is based on &lt;a href="https://electronjs.org/" target="_blank" rel="noopener noreferrer"&gt;Electron&lt;/a&gt;, so it is a web application. Hence, the idea was to automate the tests using the &lt;a href="https://www.seleniumhq.org/docs/03_webdriver.jsp" target="_blank" rel="noopener noreferrer"&gt;Selenium WebDriver&lt;/a&gt;. For that purpose, we needed to:&lt;/p&gt; &lt;ol&gt; &lt;li style="list-style-type: none;"&gt; &lt;ol&gt; &lt;li&gt;Download the appropriate version of &lt;a href="https://chromedriver.chromium.org/" target="_blank" rel="noopener noreferrer"&gt;ChromeDriver&lt;/a&gt;, which meant knowing the version of Chromium packaged inside the Electron browser our VS Code uses.&lt;/li&gt; &lt;li&gt;Add ChromeDriver to our PATH.&lt;/li&gt; &lt;li&gt;Choose the appropriate VS Code binary (which is different in every OS).&lt;/li&gt; &lt;li&gt;Set up our VS Code to run the tests properly. We cannot, for instance, use the native title bar.&lt;/li&gt; &lt;li&gt;Download another instance of VS Code just for testing. (We do not want to mess up the instance of VS Code we actually use.)&lt;/li&gt; &lt;li&gt;Build our extension.&lt;/li&gt; &lt;li&gt;Install the extension into the new instance.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Finally, we were all set to begin writing our tests, but Figure 1 shows what we would have had to sift through in order to push a button and open a view:&lt;/p&gt; &lt;div id="attachment_646527" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Screenshot-from-2019-10-30-09-24-42.png"&gt;&lt;img aria-describedby="caption-attachment-646527" class="wp-image-646527 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Screenshot-from-2019-10-30-09-24-42-1024x562.png" alt="" width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/Screenshot-from-2019-10-30-09-24-42-1024x562.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/Screenshot-from-2019-10-30-09-24-42-300x165.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/Screenshot-from-2019-10-30-09-24-42-768x421.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-646527" class="wp-caption-text"&gt;Figure 1: The mass of VS Code DOM contents we would have to sift through.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;That’s 15 layers of block elements just to find an icon representing a view container, which is quite a tall order to find a simple element. You can imagine what the rest of the DOM looks like.But enough scare tactics, we are here to make testing exciting. Almost as exciting as coding itself, because we are turning testing into coding. Let’s see how easy all of this becomes once we employ the &lt;code&gt;vscode-extension-tester&lt;/code&gt; framework.&lt;/p&gt; &lt;h2&gt;Making it simple&lt;/h2&gt; &lt;p&gt;To demonstrate, we will take an extension and create end-to-end tests for it using our framework. As a first step, I like to use something simple, like the &lt;a href="https://github.com/microsoft/vscode-extension-samples/tree/master/helloworld-sample" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;helloworld&lt;/code&gt; sample extension&lt;/a&gt; from Microsoft’s &lt;a href="https://github.com/microsoft/vscode-extension-samples" target="_blank" rel="noopener noreferrer"&gt;extension samples repo&lt;/a&gt;. This extension contributes a new command called &lt;code&gt;Hello World&lt;/code&gt; that shows a notification saying &lt;code&gt;Hello World!&lt;/code&gt; Now we need to write tests to verify that the command works properly.&lt;/p&gt; &lt;div id="attachment_646667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/10/demo.gif"&gt;&lt;img aria-describedby="caption-attachment-646667" class="wp-image-646667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/demo-1024x685.gif" alt="" width="640" height="428" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/demo-1024x685.gif 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/demo-300x201.gif 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/demo-768x513.gif 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-646667" class="wp-caption-text"&gt;Figure 2: The Hello World command: Enlarge to play.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Getting the dependencies&lt;/h3&gt; &lt;p&gt;First, we need to get the necessary dependencies. To start, we need the Extension Tester itself, along with the test framework it integrates into: &lt;a href="https://www.npmjs.com/package/mocha" target="_blank" rel="noopener noreferrer"&gt;Mocha&lt;/a&gt;. We can get both from the &lt;code&gt;npm&lt;/code&gt; registry:&lt;/p&gt; &lt;pre&gt;$ npm install --save-dev vscode-extension-tester mocha @types/mocha&lt;/pre&gt; &lt;p&gt;I will also use &lt;a href="https://www.npmjs.com/package/chai" target="_blank" rel="noopener noreferrer"&gt;Chai&lt;/a&gt; for assertions. You can use whichever assertion library you like:&lt;/p&gt; &lt;pre&gt;$ npm install --save-dev chai @types/chai&lt;/pre&gt; &lt;h3&gt;Setting up the test&lt;/h3&gt; &lt;p&gt;Now that we have our dependencies installed, we can start putting all the pieces together. Let us start by creating a test file. Our test files will rest in the &lt;code&gt;src/ui-test&lt;/code&gt;&lt;i&gt; &lt;/i&gt;folder, but you can use any path that is covered by your tsconfig, because we will write our tests in TypeScript just like the rest of the extension. Let’s go ahead and create the folder we chose and create a test file inside. I will call mine &lt;code&gt;helloworld-test.ts&lt;/code&gt;. Our file structure should now look like Figure 3:&lt;/p&gt; &lt;div id="attachment_646707" style="width: 418px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/10/files.png"&gt;&lt;img aria-describedby="caption-attachment-646707" class="wp-image-646707 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/files.png" alt="" width="408" height="315" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/files.png 408w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/files-300x232.png 300w" sizes="(max-width: 408px) 100vw, 408px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-646707" class="wp-caption-text"&gt;Figure 3: Our beginning file structure.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we need a way to launch our tests. For that purpose, we create a new script in our &lt;code&gt;package.json&lt;/code&gt; file. Let’s call our new script &lt;code&gt;ui-test&lt;/code&gt;&lt;i&gt;, &lt;/i&gt;and use the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Test-Setup#using-the-cli" target="_blank" rel="noopener noreferrer"&gt;CLI&lt;/a&gt; that comes with the Extension Tester, called &lt;code&gt;extest&lt;/code&gt;. &lt;i&gt; &lt;/i&gt;For this demo, we want to use the default configuration with the latest version of VS Code, the default settings, and the default storage location (which we will come back to momentarily).&lt;/p&gt; &lt;p&gt;We also want to perform all of the setup and then run our tests within a single command. For that purpose, we can use the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Test-Setup#set-up-and-run-tests"&gt;&lt;code&gt;setup-and-run&lt;/code&gt;&lt;/a&gt; command that takes the path to our test files as an argument in the form of a &lt;a href="https://www.npmjs.com/package/glob" target="_blank" rel="noopener noreferrer"&gt;glob&lt;/a&gt;. Note that we cannot use the original &lt;code&gt;.ts&lt;/code&gt; files to launch the tests. Instead, we need to use the compiled &lt;code&gt;.js&lt;/code&gt; files, which in this case are located in the &lt;code&gt;out/&lt;/code&gt; folder. The script will then look something like this:&lt;/p&gt; &lt;pre&gt;"ui-test": "extest setup-and-run out/ui-test/*.js"&lt;/pre&gt; &lt;p&gt;It is also important to compile our tests before attempting to run them, which we can do along with the rest of the code. For that purpose, this extension has a compile script we can use. The final script will then look like this:&lt;/p&gt; &lt;pre&gt;"ui-test": "npm run compile &amp;#38;&amp;#38; extest setup-and-run out/ui-test/*.js"&lt;/pre&gt; &lt;h3&gt;Setting up the build&lt;/h3&gt; &lt;p&gt;Now is the time to talk about the importance of the storage folder I mentioned earlier. This is where the framework stores everything it needs for the tests to run, including a fresh instance of VS Code, the ChromeDriver binary, and potentially screenshots from failed tests. It is imperative to exclude this folder from compilation and &lt;code&gt;vsce&lt;/code&gt; packaging. Otherwise, you are bound to run into build errors. We also recommend adding the storage folder into your &lt;code&gt;.gitignore&lt;/code&gt; file. By default, this folder is called &lt;code&gt;test-resources&lt;/code&gt;, and is created in the root of your extension repository.&lt;/p&gt; &lt;p&gt;First, let us exclude the folder from compilation. We need to open the &lt;code&gt;tsconfig.json&lt;/code&gt; file and add the storage folder into the &lt;code&gt;"exclude"&lt;/code&gt; array. This is what my tsconfig now looks like:&lt;/p&gt; &lt;pre&gt;{ "compilerOptions": { "module": "commonjs", "target": "es6", "outDir": "out", "sourceMap": true, "strict": true, "rootDir": "src" }, "exclude": ["node_modules", ".vscode-test", "test-resources"] }&lt;/pre&gt; &lt;p&gt;With that code, our extension should not run into build errors with the folder present. Next, we need to make sure the folder is not included in the final &lt;code&gt;.vsix&lt;/code&gt; file when we package the extension. For that purpose, we can utilize the &lt;code&gt;.vscodeignore&lt;/code&gt; file. Let&amp;#8217;s go ahead and create one in the root of our repository if it doesn’t already exist. Then, put the folder into it just like we would with &lt;code&gt;.gitignore&lt;/code&gt;, as shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_647137" style="width: 311px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/10/vsignore.png"&gt;&lt;img aria-describedby="caption-attachment-647137" class="wp-image-647137 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/vsignore.png" alt="" width="301" height="71" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/vsignore.png 301w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/vsignore-300x71.png 300w" sizes="(max-width: 301px) 100vw, 301px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-647137" class="wp-caption-text"&gt;Figure 4: Excluding the test-resources directory from packaging.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;With these three simple steps completed, we are ready to dive into writing our tests. If you wish to get additional information about the test setup, check out the framework’s &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Test-Setup" target="_blank" rel="noopener noreferrer"&gt;wiki&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Writing the tests&lt;/h2&gt; &lt;p&gt;Remember that dreadful screenshot from the VS Code DOM? If you are familiar with WebDriver testing, you know how tedious it can become when the element structure is that complex.&lt;/p&gt; &lt;h3&gt;Introducing page objects&lt;/h3&gt; &lt;p&gt;Luckily, we do not need to bother ourselves with the DOM now. The Extension Tester framework brings us a comprehensive &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Page-Object-APIs" target="_blank" rel="noopener noreferrer"&gt;Page Object API&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Each type of component in VS Code is represented by a particular typescript class and can be manipulated by a set of easy-to-understand methods. We recommend going through the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Page-Object-APIs" target="_blank" rel="noopener noreferrer"&gt;page objects quick guide&lt;/a&gt; to get an understanding of what each object represents in the browser. Additionally, each object extends the vanilla WebDriver’s WebElement, so you can use plain WebDriver code to your heart’s desire.&lt;/p&gt; &lt;h3&gt;Back to the test at hand&lt;/h3&gt; &lt;p&gt;First, we need to create a test suite and a test case using the &lt;a href="https://mochajs.org/#bdd" target="_blank" rel="noopener noreferrer"&gt;Mocha BDD&lt;/a&gt; format. The first step of our test case is to execute the command &lt;code&gt;Hello World&lt;/code&gt;. For that purpose, we can use the &lt;code&gt;Workbench&lt;/code&gt; class and its &lt;code&gt;executeCommand&lt;/code&gt; method. Our test file now looks a bit like this:&lt;/p&gt; &lt;pre&gt;import { Workbench } from 'vscode-extension-tester'; describe('Hello World Example UI Tests', () =&amp;#62; { it('Command shows a notification with the correct text', async () =&amp;#62; { const workbench = new Workbench(); await workbench.executeCommand('Hello World'); }); }); &lt;/pre&gt; &lt;p&gt;Simple, isn&amp;#8217;t it? Now, we need to assert that the correct notification has appeared. This command will take time to execute and display the result, so we cannot do this assertion straight away. Therefore, we use WebDriver to wait for the notification to appear. For that, we need a suitable wait condition.&lt;/p&gt; &lt;p&gt;Our wait condition needs to view the currently displayed notifications and return the notification that matches our needs. In this case, the notification would be one that contains, say, the text &lt;code&gt;Hello&lt;/code&gt;. If no such condition is found, do not return anything (return undefined). This way, the wait will terminate once the first truthy value is returned:&lt;/p&gt; &lt;pre&gt;async function notificationExists(text: string): Promise&amp;#60;Notification | undefined&amp;#62; { const notifications = await new Workbench().getNotifications(); for (const notification of notifications) { const message = await notification.getMessage(); if (message.indexOf(text) &amp;#62;= 0) { return notification; } } }&lt;/pre&gt; &lt;p&gt;With this condition set up, we now start waiting. To do this, we need a reference to the underlying WebDriver instance. We can get that reference from the &lt;code&gt;VSBrowser&lt;/code&gt; object, which is the entry point to the Extension Tester API. We will use the &lt;code&gt;before&lt;/code&gt; function to initialize the WebDriver instance before the tests run by adding the following lines to the beginning of our suite:&lt;/p&gt; &lt;pre&gt; let driver: WebDriver; before(() =&amp;#62; { driver = VSBrowser.instance.driver; });&lt;/pre&gt; &lt;p&gt;Initiating the wait is now as simple as this:&lt;/p&gt; &lt;pre&gt;const notification = await driver.wait(() =&amp;#62; { return notificationExists('Hello'); }, 2000) as Notification;&lt;/pre&gt; &lt;p&gt;Note the cast at the end. Our wait condition may return undefined, and we need to work with a &lt;code&gt;Notification&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;The last step is to assert that our notification has the correct attributes by checking if the notification has the correct text, and is of an &lt;code&gt;info&lt;/code&gt; type. Using Chai&amp;#8217;s &lt;code&gt;expect&lt;/code&gt; to accomplish this task looks like this:&lt;/p&gt; &lt;pre&gt; expect(await notification.getMessage()).equals('Hello World!'); expect(await notification.getType()).equals(NotificationType.Info);&lt;/pre&gt; &lt;p&gt;At this point, our first test is finished. The whole test file should look as follows:&lt;/p&gt; &lt;pre&gt;import { Workbench, Notification, WebDriver, VSBrowser, NotificationType } from 'vscode-extension-tester'; import { expect } from 'chai'; describe('Hello World Example UI Tests', () =&amp;#62; { let driver: WebDriver; before(() =&amp;#62; { driver = VSBrowser.instance.driver; }); it('Command shows a notification with the correct text', async () =&amp;#62; { const workbench = new Workbench(); await workbench.executeCommand('Hello World'); const notification = await driver.wait(() =&amp;#62; { return notificationExists('Hello'); }, 2000) as Notification; expect(await notification.getMessage()).equals('Hello World!'); expect(await notification.getType()).equals(NotificationType.Info); }); }); async function notificationExists(text: string): Promise&amp;#60;Notification | undefined&amp;#62; { const notifications = await new Workbench().getNotifications(); for (const notification of notifications) { const message = await notification.getMessage(); if (message.indexOf(text) &amp;#62;= 0) { return notification; } } }&lt;/pre&gt; &lt;h2&gt;Launching the tests&lt;/h2&gt; &lt;p&gt;All that is left now is to launch our tests. To do that, we can head to our favorite terminal and launch the script we created during the setup phase:&lt;/p&gt; &lt;pre&gt;$ npm run ui-test&lt;/pre&gt; &lt;p&gt;Now we can watch as the tooling runs the setup for us automatically:&lt;/p&gt; &lt;div style="width: 640px;" class="wp-video"&gt;&lt;!--[if lt IE 9]&gt;&lt;script&gt;document.createElement('video');&lt;/script&gt;&lt;![endif]--&gt; &lt;video class="wp-video-shortcode" id="video-646517-1" width="640" height="360" preload="metadata" controls="controls"&gt;&lt;source type="video/webm" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/extest_screencast.webm?_=1" /&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/extest_screencast.webm"&gt;https://developers.redhat.com/blog/wp-content/uploads/2019/11/extest_screencast.webm&lt;/a&gt;&lt;/video&gt;&lt;/div&gt; &lt;p&gt;Our test run was a success: We verified our extension&amp;#8217;s feature works. And best of all, we do not need to do all of this work manually anymore.&lt;/p&gt; &lt;h2&gt;Learning more&lt;/h2&gt; &lt;p&gt;If you wish to learn more about using the Extension Tester, be sure to visit the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester" target="_blank" rel="noopener noreferrer"&gt;GitHub repository&lt;/a&gt; or the &lt;a href="https://www.npmjs.com/package/vscode-extension-tester" target="_blank" rel="noopener noreferrer"&gt;npm registry page&lt;/a&gt;. The &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki" target="_blank" rel="noopener noreferrer"&gt;wiki&lt;/a&gt;, in particular, might be of interest.&lt;/p&gt; &lt;p&gt;To find detailed descriptions of all the steps we have gone through in this article, see the links below:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Test-Setup" target="_blank" rel="noopener noreferrer"&gt;Test setup&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Writing-Simple-Tests" target="_blank" rel="noopener noreferrer"&gt;Example test case&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-extension-tester/wiki/Page-Object-APIs" target="_blank" rel="noopener noreferrer"&gt;Page Object API quick guide&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Interested in the sample project we used in this article? Check out its code in the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/tree/master/sample-projects" target="_blank" rel="noopener noreferrer"&gt;sample projects&lt;/a&gt; section, complete with commented tests.&lt;/p&gt; &lt;p&gt;We also already have a few working test suites for real extensions (not just example ones). Feel free to take a look for inspiration:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href="https://github.com/camel-tooling/camel-lsp-client-vscode/tree/master/src/ui-test" target="_blank" rel="noopener noreferrer"&gt;Apache Camel extension test suite&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Fuse tooling&amp;#8217;s &lt;a href="https://github.com/djelinek/vscode-uitests-tooling" target="_blank" rel="noopener noreferrer"&gt;UI test tooling&lt;/a&gt;, extending the Extension Tester.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/redhat-developer/vscode-extension-tester/tree/master/test/test-project" target="_blank" rel="noopener noreferrer"&gt;Extension Tester&amp;#8217;s own test suite&lt;/a&gt;, which covers almost every available page object.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you would like to get involved, check out the &lt;a href="https://github.com/redhat-developer/vscode-extension-tester/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer"&gt;Contributor&amp;#8217;s guide&lt;/a&gt;. We are always happy to see your feedback and suggestions, or indeed your code contributions.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#38;linkname=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F18%2Fnew-tools-for-automating-end-to-end-tests-for-vs-code-extensions%2F&amp;#038;title=New%20tools%20for%20automating%20end-to-end%20tests%20for%20VS%20Code%20extensions" data-a2a-url="https://developers.redhat.com/blog/2019/11/18/new-tools-for-automating-end-to-end-tests-for-vs-code-extensions/" data-a2a-title="New tools for automating end-to-end tests for VS Code extensions"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/18/new-tools-for-automating-end-to-end-tests-for-vs-code-extensions/"&gt;New tools for automating end-to-end tests for VS Code extensions&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/k8n_JCKObGY" height="1" width="1" alt=""/&gt;</content><summary>It is a common practice to test software from the user’s perspective before releasing it. With this assumption, I have set out on a quest to find a VS Code extension with automated end-to-end tests. My quest ended in failure. Naturally, a lazy person like me then asked: “Why would nobody try to automate this?” It turns out that automating this was, in fact, quite difficult. My quest then became fi...</summary><dc:creator>Jan Richter</dc:creator><dc:date>2019-11-18T08:00:19Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/18/new-tools-for-automating-end-to-end-tests-for-vs-code-extensions/</feedburner:origLink></entry><entry><title>Blueprint for omnichannel integration architecture (webinar)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PlXlwhOGXUw/blueprint-for-omnichannel-integration-architecture-webinar.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="event" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="video" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-blueprint_for_omnichannel_integration_architecture_webinar</id><updated>2019-11-18T06:00:03Z</updated><published>2019-11-18T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-2MhOPmyu9_g/Xck4Ts9W9NI/AAAAAAAAwuQ/x0SHf8VD42YxIDBhL80U5tAa25US2rBRgCNcBGAsYHQ/s1600/Screenshot%2B2019-11-11%2Bat%2B10.30.25.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;span id="goog_1889717338"&gt;&lt;/span&gt;&lt;img alt="omnichannel integration architecture" border="0" data-original-height="434" data-original-width="1402" height="99" src="https://1.bp.blogspot.com/-2MhOPmyu9_g/Xck4Ts9W9NI/AAAAAAAAwuQ/x0SHf8VD42YxIDBhL80U5tAa25US2rBRgCNcBGAsYHQ/s320/Screenshot%2B2019-11-11%2Bat%2B10.30.25.png" title="" width="320" /&gt;&lt;span id="goog_1889717339"&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;Are you interested in the insights to how organizations are implementing the foundational integration building blocks that lead to successful communication with their customers?&lt;br /&gt;&lt;br /&gt;This story is about how an omnichannel customer experience makes customer engagement across all channels as efficient as engagement with a single channel. Let's take a detailed look at an architecture blueprint based on research of actual customer solutions, and gain insight into how your integration architecture can map to support your customers’ omnichannel experiences.&lt;br /&gt;&lt;br /&gt;&lt;a href="http://redhat.com/en/events/webinar/blueprint-omnichannel-integration-architecture" target="_blank"&gt;Register for this webinar&lt;/a&gt; and you'll gain insights on how your current architecture can map to support your customers experiences, for a detailed look at an architectural blueprint based on successful customer solutions, and receive instruction on how to discuss an omnichannel architecture in detail.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://1.bp.blogspot.com/-jTtB0UP6wE0/Xck6GCOSwKI/AAAAAAAAwuc/1Ijzd-z5p0Y35Z86tKkyO75IPvz8PdWRQCNcBGAsYHQ/s1600/Screenshot%2B2019-11-11%2Bat%2B10.37.59.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="omnichannel integration architecture" border="0" data-original-height="895" data-original-width="1600" height="179" src="https://1.bp.blogspot.com/-jTtB0UP6wE0/Xck6GCOSwKI/AAAAAAAAwuc/1Ijzd-z5p0Y35Z86tKkyO75IPvz8PdWRQCNcBGAsYHQ/s320/Screenshot%2B2019-11-11%2Bat%2B10.37.59.png" title="" width="320" /&gt;&lt;/a&gt;Here's the official abstract, so join us on &lt;a href="http://redhat.com/en/events/webinar/blueprint-omnichannel-integration-architecture" target="_blank"&gt;12 Dec 2019 for a detailed look&lt;/a&gt; at a blueprint for omnichannel integration architecture:&lt;br /&gt;&lt;br /&gt;&lt;i&gt;Agile integration is a broadly scoped discussion around how to use all the services and power contained in your organization’s current architecture. While the topic is interesting in its own right, let's take a deeper look at a specific solution within the integration context: providing an omnichannel customer experience. Omnichannel is the integration and orchestration of channels to make the experience of customer engagement across all channels as efficient as engagement with 1 channel.&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;a href="http://redhat.com/en/events/webinar/blueprint-omnichannel-integration-architecture" target="_blank"&gt;Be sure to register&lt;/a&gt; and look forward to seeing you there?&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=m8ksAbIjYV8:C2YEgmH1B4U:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=m8ksAbIjYV8:C2YEgmH1B4U:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=m8ksAbIjYV8:C2YEgmH1B4U:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=m8ksAbIjYV8:C2YEgmH1B4U:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=m8ksAbIjYV8:C2YEgmH1B4U:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/m8ksAbIjYV8" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PlXlwhOGXUw" height="1" width="1" alt=""/&gt;</content><summary>Are you interested in the insights to how organizations are implementing the foundational integration building blocks that lead to successful communication with their customers? This story is about how an omnichannel customer experience makes customer engagement across all channels as efficient as engagement with a single channel. Let's take a detailed look at an architecture blueprint based on re...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-11-18T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/m8ksAbIjYV8/blueprint-for-omnichannel-integration-architecture-webinar.html</feedburner:origLink></entry><entry><title>Report from July 2019 ISO C++ Standards Committee Meeting (Concurrency and Parallelism Study Group)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/e4Y_ZpRXp9I/" /><category term="C" scheme="searchisko:content:tags" /><category term="C++" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><author><name>Thomas Rodgers</name></author><id>searchisko:content:id:jbossorg_blog-report_from_july_2019_iso_c_standards_committee_meeting_concurrency_and_parallelism_study_group</id><updated>2019-11-15T08:00:52Z</updated><published>2019-11-15T08:00:52Z</published><content type="html">&lt;p&gt;The &lt;a href="https://isocpp.org/std/meetings-and-participation/upcoming-meetings"&gt;summer 2019 WG21 C++ Committee meeting&lt;/a&gt; was held in Cologne, Germany during the week of July 13. As usual,&lt;br /&gt; Red Hat sent three representatives, &lt;a href="https://developers.redhat.com/blog/2019/09/03/report-from-july-2019-iso-c-meeting-core-language/"&gt;Jason Merrill in the Core Working Group (CWG)&lt;/a&gt;, Jonathan Wakely in the Library Working Group (LWG), and myself in the Concurrency and Parallelism Study Group (SG1). This rather late report covers the Cologne SG1 session and looks ahead to some revised papers from that meeting, which are scheduled for the fall meeting in Belfast, Northern Ireland, for the first week of November 2019.&lt;span id="more-648547"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;C++20 Synchronization Library&lt;/h2&gt; &lt;p&gt;Monday started as usual after the main plenary session. SG1 started the week by reviewing some non-controversial&lt;br /&gt; additions to C++20 synchronization primitives. The first of these papers was &lt;a href="https://wg21.link/p1633R0"&gt;p1633R0&lt;/a&gt; &amp;#8220;Amendments to the C++20&lt;br /&gt; Synchronization Library,&amp;#8221; which dealt some minor issues discovered during wording review of the C++20&lt;br /&gt; Synchronization Library (&lt;a href="https://wg21.link/p1135R4"&gt;p1135R4)&lt;/a&gt;. The changes were applied to R5 of the paper, and SG1 voted to forward &lt;a href="https://wg21.link/p1135R5"&gt;p1135R5&lt;/a&gt;&lt;br /&gt; to LWG. Next up were &lt;a href="https://wg21.link/p1643R0"&gt;p1643R0&lt;/a&gt; and &lt;a href="https://wg21.link/p1644R0"&gt;p1644R0&lt;/a&gt;, which propose to add wait/notify functionality to atomic_ref and&lt;br /&gt; atomic, respectively. SG1 voted to forward both of these papers to the Library Evolution Working Group (LEWG).&lt;br /&gt; The final paper before lunch was &lt;a href="https://wg21.link/p0943R2"&gt;p0943R2&lt;/a&gt;, which concerns supporting C atomics in C++. SG1 voted to let the paper&lt;br /&gt; proceed without needing to return for further review.&lt;/p&gt; &lt;p&gt;After the break, SG1 took up the subject of stackful co-routines (aka &amp;#8220;fibers&amp;#8221;) with two papers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://wg21.link/p1520R0"&gt;P1520&lt;/a&gt; &amp;#8220;Response to response to &amp;#8220;Fibers under the magnifying glass.&amp;#8221;&amp;#8221; This paper seeks to clarify some aspects of the distinction between stackless co-routines and stackful fibers.&lt;/li&gt; &lt;li&gt;&lt;a href="https://wg21.link/p0876R5"&gt;P0876&lt;/a&gt; &amp;#8220;fiber_context &amp;#8211; fibers without scheduler.&amp;#8221; This is the latest (R6) paper in the series of proposals to bring fibers to the C++ standard. SG1 consensus was that P0876 needs changes to proceed. Further discussion on Friday reached agreement to target a Technical Specification as a ship vehicle for the proposal with the requested changes applied.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Executors&lt;/h2&gt; &lt;p&gt;Next, it was on to everyone&amp;#8217;s favorite topic: Executors. The first paper &lt;a href="https://wg21.link/p1525R0"&gt;P1525&lt;/a&gt; &amp;#8220;One-Way execute is a Poor Basis Operation.&amp;#8221; This paper argues in favor of the previous proposal for Executor Sender/Receiver as described in &lt;a href="https://wg21.link/p1341r0"&gt;P1341&lt;/a&gt; as the basis operation(s) supported by Executors, with other operations built in terms of senders and receivers, as opposed to &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt;&amp;#8216;s OneWayExecutor concept. The SG1 presentation and subsequent discussion were primarily to inform Tuesday&amp;#8217;s discussions on &lt;a href="https://wg21.link/p0443"&gt;p0443&lt;/a&gt;. The last paper of the day was &lt;a href="https://wg21.link/p1738"&gt;P1738 &lt;/a&gt;&amp;#8220;The Executor Concept Hierarchy Needs a Single Root.&amp;#8221; This paper seeks to argue that, because P0443&amp;#8217;s Executor concepts and mechanism for adding new concepts don&amp;#8217;t form a subsumption hierarchy, it&amp;#8217;s difficult to design generic components that accept executors. As with &lt;a href="https://wg21.link/p1525"&gt;P1525&lt;/a&gt;, this was an informational presentation to inform Tuesday&amp;#8217;s discussions on &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Tuesday morning, SG1 kicked off by reviewing &lt;a href="https://wg21.link/p1068"&gt;P1068&lt;/a&gt; &amp;#8220;Vector API for random number generation.&amp;#8221; This paper&lt;br /&gt; proposes to add SIMD support for random number generation. The discussion led to weak consensus that such a facility should produce a SIMD type as described in &lt;a href="https://wg21.link/n4796"&gt;N4796&lt;/a&gt; &amp;#8220;Technical Specification for C++ Extensions for Parallelism.&amp;#8221; A revision of this paper will likely be discussed at the fall WG21 meeting.&lt;/p&gt; &lt;p&gt;Next up was &lt;a href="https://wg21.link/p1367"&gt;P1367&lt;/a&gt; &amp;#8220;Not All Agents Have TLS.&amp;#8221; This paper proposes standardizing the existing practice of thread_local, as the reality of TLS usage is much more complicated than the wording in the Standard even allows us to explain. This is a rather complicated topic and SG1 had an extensive discussion on the issues, but no straw polls were taken at this meeting.&lt;/p&gt; &lt;p&gt;Tuesday afternoon, SG1 resumed discussion on Executors with &lt;a href="https://wg21.link/p1658"&gt;P1658&lt;/a&gt; &amp;#8220;Suggestions for Consensus on Executors.&amp;#8221; This paper proposes to modify the executors model as described by &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt; to increase consensus in the hope that executors are merged with C++23 as planned. The compromise seeks to essentially create a singly rooted executor concept hierarchy and add support for customization of bulk_execute as well as introducing the Sender/Receiver concepts. The main point of contention remaining from the compromise is error handling.&lt;/p&gt; &lt;p&gt;We then discussed &lt;a href="https://wg21.link/p1791"&gt;P1791&lt;/a&gt; &amp;#8220;Evolution of the &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt; Unified Executors Proposal to accommodate new requirements.&amp;#8221; The central premise of this paper is the properties mechanism outlined in &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt; can support the requirements of &lt;a href="https://wg21.link/p1660"&gt;P1660&lt;/a&gt;&amp;#8216;s sender/receiver model. Again, significant discussion time was spent on what sort of error channel(s) should be supported. Next, &lt;a href="https://wg21.link/p1792"&gt;P1792&lt;/a&gt; &amp;#8220;Simplifying and generalising Sender/Receiver for asynchronous operations&amp;#8221; argues that the API design approach of &lt;a href="https://wg21.link/p1341"&gt;P1341&lt;/a&gt; &amp;#8220;Unifying Asynchronous APIs in C++ Standard Library&amp;#8221; presents problems with usability, flexibility, and efficiency compared to existing practice. No straw polls were taken; significant differences of opinion remain. The last paper of the day was &lt;a href="https://wg21.link/p1660"&gt;P1660&lt;/a&gt;. After extensive discussion, SG1 voted to apply &lt;a href="https://wg21.link/p1658"&gt;P1658&lt;/a&gt;&amp;#8216;s proposed changes to &lt;a href="https://wg21.link/p0443"&gt;P0443&lt;/a&gt;, and that it would be &amp;#8220;tolerable'&amp;#8221; to ship error handling as in P1660. There was no consensus to proceed with error&lt;br /&gt; handling as in &lt;a href="https://wg21.link/p1791"&gt;P1791&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Memory model topics&lt;/h2&gt; &lt;p&gt;Wednesday, SG1 turned its attention to all things memory model, starting with an update on &lt;a href="https://wg21.link/p1217"&gt;P1217 &lt;/a&gt;&amp;#8220;Out-of-thin-air, revisited, again.&amp;#8221; Next up, &lt;a href="https://wg21.link/p1780"&gt;P1780&lt;/a&gt; &amp;#8220;Modular Relaxed Dependencies: A new approach to the Out-Of-Thin-Air Problem.&amp;#8221; Next, SG1 reviewed &lt;a href="https://wg21.link/p1478"&gt;P1478R0&lt;/a&gt; &amp;#8220;Byte-wise atomic memcpy,&amp;#8221; which was presented as a draft at the Spring 2019 meeting and essentially looks to codify what most memcpy implementations already do. The shipping vehicle is likely a Technical Specification.&lt;/p&gt; &lt;p&gt;Wednesday afternoon, SG1 reviewed &lt;a href="https://wg21.link/p1116"&gt;P1116&lt;/a&gt; &amp;#8220;Re-Gaining Exclusive Ownership from shared_ptrs,&amp;#8221; which is a proposal to add a &amp;#8220;lock_exclusive()&amp;#8221; operation to shared_ptr. SG1 determined it is implementable but not without ABI breakage, and they don&amp;#8217;t like the name of the operation. Next up, we reviewed &lt;a href="https://wg21.link/p1726"&gt;P1726&lt;/a&gt; &amp;#8220;Pointer lifetime-end zap.&amp;#8221; This paper seeks to reconcile what the Standard says about the state of pointer after an object&amp;#8217;s lifetime has ended, with well-known algorithms that rely on being able to perform certain operations on pointers whose lifetimes have ended. There are various suggestions to address this issue, but no conclusions were reached at this meeting.&lt;/p&gt; &lt;p&gt;Next, we looked at &lt;a href="https://wg21.link/p0940"&gt;P0940&lt;/a&gt; &amp;#8220;Concurrency TS is growing: Concurrent Utilities and Data Structures&amp;#8221; and &lt;a href="https://wg21.link/p1445"&gt;P1445&lt;/a&gt; &amp;#8220;Concurrency TS: to update or not update.&amp;#8221; The discussion of these papers mostly had to do with timing of issuing a new Technical Specification and what language standard it should be based on. From here, the discussion moved on to &amp;#8220;Clarifying atomic&amp;#60;thread::id&amp;#62;::compare_exchange_*&amp;#8221; (&lt;a href="https://wg21.link/p1801"&gt;P1801&lt;/a&gt;). SG1 voted to approve the proposed resolution presented in the paper.&lt;/p&gt; &lt;h2&gt;Low-level I/O and more executors&lt;/h2&gt; &lt;p&gt;Thursday morning, SG1 considered a pair of related papers that deal with supporting low-level IO facilities and the ability to detach objects, transport them elsewhere, and resume the object lifetime. The papers were &lt;a href="https://wg21.link/p1031"&gt;P1031&lt;/a&gt; &amp;#8220;Low-level file i/o library&amp;#8221; and &lt;a href="https://wg21.link/p1631"&gt;P1631&lt;/a&gt; &amp;#8220;Object detachment and attachment.&amp;#8221; The scope of these papers is quite large, even to just survey the issues, and SG1 determined that these proposals fall squarely in SG1&amp;#8217;s remit. Next SG1 considered&lt;br /&gt; &lt;a href="https://wg21.link/p0652"&gt;P0652&lt;/a&gt; &amp;#8220;Concurrent associative data structure with unsynchronized view,&amp;#8221; which had been updated based on SG1&amp;#8217;s guidance at the Spring 2019 meeting. SG1 discussed the various issues with such a datatype, but no straw polls were taken. Next SG1 looked at &lt;a href="https://wg21.link/p1761"&gt;P1761&lt;/a&gt; &amp;#8220;Concurrent map customization options.&amp;#8221; These concurrent data structure papers are likely headed to a Technical Specification.&lt;/p&gt; &lt;p&gt;On Thursday afternoon, SG1 reviewed a handful of executor-related papers, starting with &lt;a href="https://wg21.link/p1019"&gt;P1019&lt;/a&gt; &amp;#8220;Integrating Executors with Parallel Algorithms.&amp;#8221; Next was &lt;a href="https://wg21.link/p0797r2"&gt;P0797R2&lt;/a&gt; &amp;#8220;Handling Concurrent Exceptions with Executors,&amp;#8221; followed by &lt;a href="https://wg21.link/p1436"&gt;P1436R0&lt;/a&gt; &amp;#8220;Executor properties for affinity-based execution.&amp;#8221; There was general agreement that executors should support some form of error handling facility, as not all agents support C++ exceptions.&lt;/p&gt; &lt;h2&gt;Friday papers&lt;/h2&gt; &lt;p&gt;SG1 started Friday morning looking at &lt;a href="https://wg21.link/p1382"&gt;P1382&lt;/a&gt; &amp;#8220;volatile_load&amp;#60;T&amp;#62; and volatile_store&amp;#60;T&amp;#62;,&amp;#8221; which is related to &lt;a href="https://wg21.link/p1152"&gt;P1152&lt;/a&gt; &amp;#8220;Deprecating volatile.&amp;#8221; Next up was &lt;a href="https://wg21.link/p1750"&gt;P1750&lt;/a&gt; &amp;#8220;A Proposal to Add Process Management to the C++ Standard Library.&amp;#8221; The proposal is based on the boost.process library, which provides cross-platform process management functionality, with a lot of discussion about how to support this within the standard. A new version of &lt;a href="https://wg21.link/p1750"&gt;P1750&lt;/a&gt; is available in the pre-Belfast meeting and is likely to be on SG1&amp;#8217;s agenda again. The last paper of the morning was &lt;a href="https://wg21.link/p1108"&gt;P1108&lt;/a&gt; &amp;#8220;web_view,&amp;#8221; which proposes a web_view facility for the C++ standard library that leverages existing web standards and technology. A new version of &lt;a href="https://wg21.link/p1108"&gt;P1108&lt;/a&gt; is in the pre-Belfast mailing and is likely to be on SG1&amp;#8217;s agenda again.&lt;/p&gt; &lt;p&gt;Friday afternoon, SG1 reviewed &lt;a href="https://wg21.link/p1795"&gt;P1795&lt;/a&gt; &amp;#8220;System topology discovery for heterogeneous and distributed computing.&amp;#8221; A new revision of this paper is available in the pre-Belfast meeting and is likely to be on SG1&amp;#8217;s agenda again. The last paper SG1 discussed in Cologne was &lt;a href="https://wg21.link/p0642"&gt;P0642&lt;/a&gt; &amp;#8220;The Concurrent Invocation Library.&amp;#8221; The aim of this paper is to provide structural support for invoking multiple operations concurrently in C++. SG1&amp;#8217;s feedback was to review &lt;a href="https://wg21.link/p1660"&gt;P1660&lt;/a&gt; and come back with a new version of the paper, which is part of the pre-Belfast meeting and is likely to be reviewed again.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F15%2Freport-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group%2F&amp;#038;title=Report%20from%20July%202019%20ISO%20C%2B%2B%20Standards%20Committee%20Meeting%20%28Concurrency%20and%20Parallelism%20Study%20Group%29" data-a2a-url="https://developers.redhat.com/blog/2019/11/15/report-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group/" data-a2a-title="Report from July 2019 ISO C++ Standards Committee Meeting (Concurrency and Parallelism Study Group)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/15/report-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group/"&gt;Report from July 2019 ISO C++ Standards Committee Meeting (Concurrency and Parallelism Study Group)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/e4Y_ZpRXp9I" height="1" width="1" alt=""/&gt;</content><summary>The summer 2019 WG21 C++ Committee meeting was held in Cologne, Germany during the week of July 13. As usual, Red Hat sent three representatives, Jason Merrill in the Core Working Group (CWG), Jonathan Wakely in the Library Working Group (LWG), and myself in the Concurrency and Parallelism Study Group (SG1). This rather late report covers the Cologne SG1 session and looks ahead to some revised pap...</summary><dc:creator>Thomas Rodgers</dc:creator><dc:date>2019-11-15T08:00:52Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/15/report-from-july-2019-iso-c-standards-committee-meeting-concurrency-and-parallelism-study-group/</feedburner:origLink></entry><entry><title>Keycloak 8.0.0 released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/JdWvu_LKiAs/keycloak-800-released.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><category term="Keycloak Release" scheme="searchisko:content:tags" /><author><name>Keycloak</name></author><id>searchisko:content:id:jbossorg_blog-keycloak_8_0_0_released</id><updated>2019-11-15T00:00:00Z</updated><published>2019-11-15T00:00:00Z</published><content type="html">&lt;p&gt;To download the release go to &lt;a href="https://www.keycloak.org/downloads.html"&gt;Keycloak downloads&lt;/a&gt;.&lt;/p&gt; &lt;p&gt; For details on what is included in the release check out the &lt;a href="https://www.keycloak.org/docs/latest/release_notes/index.html"&gt;Release notes&lt;/a&gt;. The full list of resolved issues are available in &lt;a href="https://issues.jboss.org/issues/?jql=project%20%3D%20keycloak%20and%20fixVersion%20%3D%208.0.0"&gt;JIRA&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Before you upgrade remember to backup your database and check the &lt;a href="https://www.keycloak.org/docs/latest/upgrading/index.html"&gt;upgrade guide&lt;/a&gt; for anything that may have changed.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/JdWvu_LKiAs" height="1" width="1" alt=""/&gt;</content><summary>To download the release go to Keycloak downloads. For details on what is included in the release check out the Release notes. The full list of resolved issues are available in JIRA Before you upgrade remember to backup your database and check the upgrade guide for anything that may have changed.</summary><dc:creator>Keycloak</dc:creator><dc:date>2019-11-15T00:00:00Z</dc:date><feedburner:origLink>https://www.keycloak.org/2019/11/keycloak-800-released.html</feedburner:origLink></entry><entry><title>Open Liberty Java runtime now available to Red Hat Runtimes subscribers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/D8KcEuakrIs/" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Open Liberty" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat Runtimes" scheme="searchisko:content:tags" /><author><name>Laura Cowen</name></author><id>searchisko:content:id:jbossorg_blog-open_liberty_java_runtime_now_available_to_red_hat_runtimes_subscribers</id><updated>2019-11-14T08:01:10Z</updated><published>2019-11-14T08:01:10Z</published><content type="html">&lt;p&gt;&lt;a href="https://openliberty.io/" target="_blank" rel="noopener noreferrer"&gt;Open Liberty&lt;/a&gt; is a lightweight, production-ready &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; runtime for containerizing and deploying microservices to the cloud, and is now available as part of a &lt;a href="https://www.redhat.com/en/products/runtimes" target="_blank" rel="noopener noreferrer"&gt;Red Hat Runtimes&lt;/a&gt; subscription. If you are a Red Hat Runtimes subscriber, you can write your &lt;a href="https://microprofile.io/" target="_blank" rel="noopener noreferrer"&gt;Eclipse MicroProfile&lt;/a&gt; and &lt;a href="https://jakarta.ee/" target="_blank" rel="noopener noreferrer"&gt;Jakarta EE&lt;/a&gt; apps on Open Liberty and then run them in containers on &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;, with commercial support from Red Hat and IBM.&lt;span id="more-649837"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Develop cloud-native Java microservices&lt;/h2&gt; &lt;p&gt;Open Liberty is designed to provide a smooth developer experience with a &lt;a href="https://openliberty.io/blog/2019/10/30/faster-startup-open-liberty.html" target="_blank" rel="noopener noreferrer"&gt;one-second startup time&lt;/a&gt;, a low memory footprint, and our new &lt;a href="https://openliberty.io/blog/2019/10/22/liberty-dev-mode.html" target="_blank" rel="noopener noreferrer"&gt;dev mode&lt;/a&gt;:&lt;/p&gt; &lt;p&gt;&lt;a href="https://twitter.com/javahippie/status/1187986394117001216"&gt;&lt;img class=" aligncenter wp-image-650757 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/OL-DevMode-Tweet.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/OL-DevMode-Tweet.png" alt="Tweet about Open Liberty Dev Mode." width="598" height="216" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/OL-DevMode-Tweet.png 598w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/OL-DevMode-Tweet-300x108.png 300w" sizes="(max-width: 598px) 100vw, 598px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Open Liberty provides a full implementation of MicroProfile 3 and &lt;a href="https://developers.redhat.com/blog/2019/09/12/jakarta-ee-8-the-new-era-of-java-ee-explained/"&gt;Jakarta EE 8&lt;/a&gt;. &lt;a href="https://developers.redhat.com/videos/youtube/fbVYQENPa4s/"&gt;MicroProfile&lt;/a&gt; is a &lt;a href="https://microprofile.io/contributors/" target="_blank" rel="noopener noreferrer"&gt;collaborative project&lt;/a&gt; between multiple vendors (including Red Hat and IBM) and the Java community that aims to optimize enterprise Java for writing microservices. With a four-week release schedule, Liberty usually has the latest MicroProfile release available soon after the spec is published.&lt;/p&gt; &lt;p&gt;Also, Open Liberty is supported in common developer tools, including VS Code, Eclipse, Maven, and Gradle. Server configuration (e.g., adding or removing a capability, or &amp;#8220;feature,&amp;#8221; to your app) is through an XML file. Open Liberty’s zero migration policy means that you can focus on what’s important (writing your app!) and not have to worry about APIs changing under you.&lt;/p&gt; &lt;h2&gt;Deploy in containers to any cloud&lt;/h2&gt; &lt;p&gt;When you’re ready to deploy your app, you can just containerize it and deploy it to OpenShift. The zero migration principle means that new versions of Open Liberty features will not break your app, and you can control which version of the feature your app uses.&lt;/p&gt; &lt;p&gt;Monitoring live microservices is enabled by MicroProfile &lt;a href="https://www.openliberty.io/guides/microprofile-metrics.html" target="_blank" rel="noopener noreferrer"&gt;Metrics&lt;/a&gt;, &lt;a href="https://www.openliberty.io/guides/kubernetes-microprofile-health.html" target="_blank" rel="noopener noreferrer"&gt;Health&lt;/a&gt;, and &lt;a href="https://www.openliberty.io/guides/microprofile-opentracing.html" target="_blank" rel="noopener noreferrer"&gt;OpenTracing&lt;/a&gt;, which add observability to your apps. The emitted metrics from your apps and from the Open Liberty runtime can be consolidated using Prometheus and presented in Grafana.&lt;/p&gt; &lt;h2&gt;Learn with the Open Liberty developer guides&lt;/h2&gt; &lt;p&gt;Our &lt;a href="https://www.openliberty.io/guides/" target="_blank" rel="noopener noreferrer"&gt;Open Liberty developer guides&lt;/a&gt; are available with runnable code and explanations to help you learn how to write microservices with &lt;a href="https://openliberty.io/guides/?search=microprofile&amp;#38;key=tag" target="_blank" rel="noopener noreferrer"&gt;MicroProfile&lt;/a&gt; and &lt;a href="https://openliberty.io/guides/?search=jakarta%20ee" target="_blank" rel="noopener noreferrer"&gt;Jakarta EE&lt;/a&gt;, and then to deploy them to Red Hat OpenShift.&lt;/p&gt; &lt;h2&gt;Get started&lt;/h2&gt; &lt;p&gt;To get started with Open Liberty, try the &lt;a href="https://openliberty.io/guides/getting-started.html" target="_blank" rel="noopener noreferrer"&gt;Packaging and deploying applications guide&lt;/a&gt; and the &lt;a href="https://openliberty.io/guides/cloud-openshift.html" target="_blank" rel="noopener noreferrer"&gt;Deploying microservices to OpenShift guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#38;linkname=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Fopen-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers%2F&amp;#038;title=Open%20Liberty%20Java%20runtime%20now%20available%20to%20Red%20Hat%20Runtimes%20subscribers" data-a2a-url="https://developers.redhat.com/blog/2019/11/14/open-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers/" data-a2a-title="Open Liberty Java runtime now available to Red Hat Runtimes subscribers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/14/open-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers/"&gt;Open Liberty Java runtime now available to Red Hat Runtimes subscribers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/D8KcEuakrIs" height="1" width="1" alt=""/&gt;</content><summary>Open Liberty is a lightweight, production-ready Java runtime for containerizing and deploying microservices to the cloud, and is now available as part of a Red Hat Runtimes subscription. If you are a Red Hat Runtimes subscriber, you can write your Eclipse MicroProfile and Jakarta EE apps on Open Liberty and then run them in containers on Red Hat OpenShift, with commercial support from Red Hat and ...</summary><dc:creator>Laura Cowen</dc:creator><dc:date>2019-11-14T08:01:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/14/open-liberty-java-runtime-now-available-to-red-hat-runtimes-subscribers/</feedburner:origLink></entry><entry><title>Tracing Kubernetes applications with Jaeger and Eclipse Che</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/9rwysMdWORY/" /><category term="Eclipse Che" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Jaeger" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="opentracing" scheme="searchisko:content:tags" /><author><name>Gary Brown</name></author><id>searchisko:content:id:jbossorg_blog-tracing_kubernetes_applications_with_jaeger_and_eclipse_che</id><updated>2019-11-14T08:00:28Z</updated><published>2019-11-14T08:00:28Z</published><content type="html">&lt;p&gt;Developing distributed applications is complicated. You can wait to monitor for performance issues once you launch the application on your test or staging servers, or in production if you’re feeling lucky, but why not track performance as you develop? This allows you to identify improvement opportunities before rolling out changes to a test or production environment. This article demonstrates how two tools can work together to integrate performance monitoring into your development environment: &lt;a href="https://www.eclipse.org/che/" target="_blank" rel="noopener noreferrer"&gt;Eclipse Che&lt;/a&gt; and &lt;a href="https://www.jaegertracing.io/" target="_blank" rel="noopener noreferrer"&gt;Jaeger&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;According to the Eclipse Che website:&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;em&gt;&amp;#8220;Che brings your Kubernetes application into your development environment and provides an in-browser IDE, allowing you to code, build, test, and run applications exactly as they run on production from any machine.&amp;#8221;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In this article, we show how simple it is to add Jaeger to your Eclipse Che development workspace and observe how your Kubernetes application performs. We will use &lt;a href="http://che.openshift.io/" target="_blank" rel="noopener noreferrer"&gt;che.openshift.io&lt;/a&gt; as the hosting environment, although you could &lt;a href="https://www.eclipse.org/che/docs/che-7/running-che-locally/" target="_blank" rel="noopener noreferrer"&gt;set up a local Che server&lt;/a&gt; if you prefer.&lt;span id="more-648657"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="create-the-workspace"&gt;Create the workspace&lt;/h2&gt; &lt;p&gt;Che 7 introduced the capability to define a development workspace in a YAML format called a &lt;a href="https://www.eclipse.org/che/docs/che-7/configuring-a-workspace-using-a-devfile/" target="_blank" rel="noopener noreferrer"&gt;devfile&lt;/a&gt;. Example devfiles can be found in the &lt;a href="https://github.com/redhat-developer/devfile" target="_blank" rel="noopener noreferrer"&gt;Red Hat Developers GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For this post, we use a modified version of the &lt;a href="https://github.com/redhat-developer/devfile/blob/master/getting-started/spring-boot/devfile.yaml" target="_blank" rel="noopener noreferrer"&gt;Spring Boot getting started devfile&lt;/a&gt;, which adds the Jaeger all-in-one backend to the workspace. The main change is to add the following section just before the &lt;code&gt;commands&lt;/code&gt; top-level node:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;- type: dockerimage alias: tracing image: jaegertracing/all-in-one:latest env: - name: MEMORY_MAX_TRACES value: "5000" - name: COLLECTOR_ZIPKIN_HTTP_PORT value: "9411" memoryLimit: 128Mi endpoints: - name: 'tracing-ui' port: 16686 - name: 'collector-grpc' port: 14250 attributes: public: 'false' - name: 'collector-http' port: 14268 attributes: public: 'false' - name: 'collector-zipkin' port: 9411 attributes: public: 'false' - name: 'agent-config' port: 5778 attributes: public: 'false' - name: '6831/udp' port: 6831 attributes: public: 'false' - name: '6832/udp' port: 6832 attributes: public: 'false' volumes: - name: tmp containerPath: /tmp &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The fully modified version of the devfile can be found &lt;a href="https://gist.github.com/objectiser/667615926a40d6cd8eb675859ddee1a1"&gt;here&lt;/a&gt;, with the additional memory limit changes required for using &lt;a href="http://che.openshift.io" target="_blank" rel="noopener noreferrer"&gt;che.openshift.io&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To start the workspace on &lt;a href="http://che.openshift.io" target="_blank" rel="noopener noreferrer"&gt;che.openshift.io&lt;/a&gt;, point a browser to &lt;a href="http://che.openshift.io/f?url=https://gist.githubusercontent.com/objectiser/667615926a40d6cd8eb675859ddee1a1/raw/06d25e2026d7a689dd8b38a343eec9a9cc431cde/che-spring-boot-devfile.yaml" target="_blank" rel="noopener noreferrer"&gt;this url&lt;/a&gt;. Chrome is recommended due to issues on some versions of Firefox.&lt;/p&gt; &lt;h2 id="add-opentracing-instrumentation"&gt;Add OpenTracing instrumentation&lt;/h2&gt; &lt;p&gt;When the workspace is initially opened, the application has no OpenTracing instrumentation, as you can see in Figure 1:&lt;/p&gt; &lt;div id="attachment_648917" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648917" class="wp-image-648917 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che1-1024x694.png" alt="Figure 1: The initial workspace." width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che1-1024x694.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che1-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che1-768x520.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che1.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-648917" class="wp-caption-text"&gt;Figure 1: The initial workspace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;OpenTracing instrumentation can implicitly be added by including a dependency on &lt;code&gt;opentracing-spring-jaeger-cloud-starter&lt;/code&gt; (shown in the updated &lt;code&gt;pom.xml&lt;/code&gt; file in Figure 2), along with updating the &lt;code&gt;spring-boot-starter-parent&lt;/code&gt; version to &lt;code&gt;2.2.0.RELEASE&lt;/code&gt; (which is required by the OpenTracing instrumentation):&lt;/p&gt; &lt;div id="attachment_648907" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648907" class="wp-image-648907" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che2-300x127.png" alt="OpenTracing" width="600" height="253" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che2-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che2-768x324.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che2.png 891w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-648907" class="wp-caption-text"&gt;Figure 2: Adding the OpenTracing instrumentation.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This dependency automatically instruments the inbound and outbound HTTP requests. It also bootstraps the Jaeger tracer to report the tracing data to the Jaeger back end (included in the workspace). The default tracer configuration will report the data via UDP to the Jaeger agent, although the application can be configured to report the data via &lt;a href="https://github.com/opentracing-contrib/java-spring-jaeger#configuration" target="_blank" rel="noopener noreferrer"&gt;HTTP directly to the collector&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The final step is to add a property that defines the service name within the tracing data. This goal is achieved by creating the &lt;code&gt;src/main/resources&lt;/code&gt; folder and then creating the file &lt;code&gt;application.properties&lt;/code&gt; with the contents shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_648897" style="width: 610px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648897" class="wp-image-648897" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che3-300x147.png" alt="" width="600" height="295" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che3-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che3-768x378.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che3.png 895w" sizes="(max-width: 600px) 100vw, 600px" /&gt;&lt;p id="caption-attachment-648897" class="wp-caption-text"&gt;Figure 3: Defining the service name within the tracing data.&lt;/p&gt;&lt;/div&gt; &lt;h2 id="trace-the-running-application"&gt;Trace the running application&lt;/h2&gt; &lt;p&gt;On the right side of the workspace is a cube symbol. When selected, this icon expands a tree. Under the &lt;strong&gt;User Runtimes/tools&lt;/strong&gt; tree node is a task called &lt;strong&gt;run webapp&lt;/strong&gt;. Selecting this option will run the Spring Boot application. When it starts, a window appears with the button &lt;strong&gt;Open Link&lt;/strong&gt; as shown in Figure 4. Press this button to start a browser for the application.&lt;/p&gt; &lt;div id="attachment_648887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648887" class="wp-image-648887 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che4-1024x694.png" alt="" width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che4-1024x694.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che4-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che4-768x520.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che4.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-648887" class="wp-caption-text"&gt;Figure 4: Opening a browser for the application.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the same tree, select the &lt;strong&gt;User Runtimes/tracing&lt;/strong&gt; option &lt;strong&gt;tracing-ui&lt;/strong&gt;, which launches the Jaeger UI in a separate browser tab as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_648877" style="width: 443px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648877" class="wp-image-648877 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che5.png" alt="" width="433" height="359" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che5.png 433w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che5-300x249.png 300w" sizes="(max-width: 433px) 100vw, 433px" /&gt;&lt;p id="caption-attachment-648877" class="wp-caption-text"&gt;Figure 5: Launching a new browser tab for tracing.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Press the refresh button at the top of the browser a couple of times to see the text &lt;code&gt;Span reported&lt;/code&gt; in the console window, as shown at the bottom of Figure 6:&lt;/p&gt; &lt;div id="attachment_648867" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648867" class="wp-image-648867 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che6-1024x694.png" alt="" width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che6-1024x694.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che6-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che6-768x520.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che6.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-648867" class="wp-caption-text"&gt;Figure 6: Running application with console log showing spans being reported.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Change to the &lt;strong&gt;Jaeger UI&lt;/strong&gt; tab to see the resulting traces that were reported from the application, as shown in Figures 7 and 8:&lt;/p&gt; &lt;div id="attachment_648857" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648857" class="wp-image-648857 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che7-1024x694.png" alt="" width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che7-1024x694.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che7-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che7-768x520.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che7.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-648857" class="wp-caption-text"&gt;Figure 7: The completed traces.&lt;/p&gt;&lt;/div&gt; &lt;div id="attachment_648847" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-648847" class="wp-image-648847 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che8-1024x694.png" alt="" width="640" height="434" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che8-1024x694.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che8-300x203.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che8-768x520.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/jaeger-che8.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-648847" class="wp-caption-text"&gt;Figure 8: Details for the first completed trace.&lt;/p&gt;&lt;/div&gt; &lt;h2 id="summary"&gt;Summary&lt;/h2&gt; &lt;p&gt;This article has shown how OpenTracing with Jaeger can easily be introduced into an Eclipse Che workspace so you can obtain tracing information from applications during development.&lt;/p&gt; &lt;p&gt;This particular example is simple and only captures tracing from a single service. The benefit offered by Che is enabling complete applications (multiple services) to be used within the same workspace, thus producing more interesting traces and helping developers understand the performance of their developed service in the context of the complete application.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#38;linkname=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F14%2Ftracing-kubernetes-applications-with-jaeger-and-eclipse-che%2F&amp;#038;title=Tracing%20Kubernetes%20applications%20with%20Jaeger%20and%20Eclipse%20Che" data-a2a-url="https://developers.redhat.com/blog/2019/11/14/tracing-kubernetes-applications-with-jaeger-and-eclipse-che/" data-a2a-title="Tracing Kubernetes applications with Jaeger and Eclipse Che"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/14/tracing-kubernetes-applications-with-jaeger-and-eclipse-che/"&gt;Tracing Kubernetes applications with Jaeger and Eclipse Che&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/9rwysMdWORY" height="1" width="1" alt=""/&gt;</content><summary>Developing distributed applications is complicated. You can wait to monitor for performance issues once you launch the application on your test or staging servers, or in production if you’re feeling lucky, but why not track performance as you develop? This allows you to identify improvement opportunities before rolling out changes to a test or production environment. This article demonstrates how ...</summary><dc:creator>Gary Brown</dc:creator><dc:date>2019-11-14T08:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/14/tracing-kubernetes-applications-with-jaeger-and-eclipse-che/</feedburner:origLink></entry><entry><title>Pod Lifecycle Event Generator: Understanding the “PLEG is not healthy” issue in Kubernetes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/k5tVaV2KsXc/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Daein Park</name></author><id>searchisko:content:id:jbossorg_blog-pod_lifecycle_event_generator_understanding_the_pleg_is_not_healthy_issue_in_kubernetes</id><updated>2019-11-13T08:00:25Z</updated><published>2019-11-13T08:00:25Z</published><content type="html">&lt;p&gt;In this article, I&amp;#8217;ll explore the &amp;#8220;PLEG is not healthy&amp;#8221; issue in &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;, which sometimes leads to a &amp;#8220;NodeNotReady&amp;#8221; status. When understanding how the Pod Lifecycle Event Generator (PLEG) works, it is helpful to also understand troubleshooting around this issue.&lt;/p&gt; &lt;h2&gt;What is PLEG?&lt;/h2&gt; &lt;p&gt;The PLEG module in kubelet (Kubernetes) adjusts the container runtime state with each matched pod-level event and keeps the pod cache up to date by applying changes.&lt;span id="more-645967"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s take a look at the dotted red line below in the process image.&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone size-full wp-image-645557" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/orig-pleg-1.png" alt="" width="761" height="437" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/orig-pleg-1.png 761w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/orig-pleg-1-300x172.png 300w" sizes="(max-width: 761px) 100vw, 761px" /&gt;&lt;/p&gt; &lt;p&gt;The original image is here: &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md"&gt;Kubelet: Pod Lifecycle Event Generator (PLEG)&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;How does &amp;#8220;PLEG is not healthy&amp;#8221; happen?&lt;/h2&gt; &lt;p&gt;Kubelet keeps checking PLEG health by calling &lt;code&gt;Healthy()&lt;/code&gt; periodically in &lt;code&gt;SyncLoop()&lt;/code&gt; as follows.&lt;/p&gt; &lt;p&gt;&lt;code&gt;Healthy()&lt;/code&gt; checks whether the &lt;code&gt;relist&lt;/code&gt; process (the PLEG key task) completes within 3 minutes. This function is added to &lt;code&gt;runtimeState&lt;/code&gt; as &amp;#8220;PLEG&amp;#8221; and is called periodically from &amp;#8220;SyncLoop&amp;#8221;(every 10s by default). If the &amp;#8220;relist&amp;#8221; process take more than 3 minutes, a &amp;#8220;PLEG is not healthy&amp;#8221; issue is reported through this stack process.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ll walk you through the related source code based on Kubernetes 1.11 (OpenShift 3.11) in each part to help your understanding. Don&amp;#8217;t worry if you are not familiar with the Go syntax, as it&amp;#8217;s enough to read the comments in the code.  I will also explain the summary before the code and snip less important things from the source code for readability.&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone size-full wp-image-645577" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-healthy-checks.png" alt="" width="682" height="401" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-healthy-checks.png 682w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-healthy-checks-300x176.png 300w" sizes="(max-width: 682px) 100vw, 682px" /&gt;&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - Healthy() // The threshold needs to be greater than the relisting period + the // relisting time, which can vary significantly. Set a conservative // threshold to avoid flipping between healthy and unhealthy. relistThreshold = 3 * time.Minute : func (g *GenericPLEG) Healthy() (bool, error) { relistTime := g.getRelistTime() elapsed := g.clock.Since(relistTime) if elapsed &amp;#62; relistThreshold { return false, fmt.Errorf("pleg was last seen active %v ago; threshold is %v", elapsed, relistThreshold) } return true, nil } //// pkg/kubelet/kubelet.go - NewMainKubelet() func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ... : klet.runtimeState.addHealthCheck("PLEG", klet.pleg.Healthy) //// pkg/kubelet/kubelet.go - syncLoop() func (kl *Kubelet) syncLoop(updates &amp;#60;-chan kubetypes.PodUpdate, handler SyncHandler) { : // The resyncTicker wakes up kubelet to checks if there are any pod workers // that need to be sync'd. A one-second period is sufficient because the // sync interval is defaulted to 10s. : const ( base = 100 * time.Millisecond max = 5 * time.Second factor = 2 ) duration := base for { if rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 { glog.Infof("skipping pod synchronization - %v", rs) // exponential backoff time.Sleep(duration) duration = time.Duration(math.Min(float64(max), factor*float64(duration))) continue } : } : } //// pkg/kubelet/runtime.go - runtimeErrors() func (s *runtimeState) runtimeErrors() []string { : for _, hc := range s.healthChecks { if ok, err := hc.fn(); !ok { ret = append(ret, fmt.Sprintf("%s is not healthy: %v", hc.name, err)) } } : }&lt;/pre&gt; &lt;h2&gt;Review &amp;#8220;relist&amp;#8221;&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s look at more details of the &lt;code&gt;relist&lt;/code&gt; function. Specifically, you&amp;#8217;ll want to watch carefully for the remote process calls and check how to process the pull data, because these parts can easily bottleneck.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-645977 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-process.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-process.png" alt="" width="839" height="621" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-process.png 839w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-process-300x222.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-process-768x568.png 768w" sizes="(max-width: 839px) 100vw, 839px" /&gt;&lt;/p&gt; &lt;p&gt;In the above flow chart, you can see the process and implementation of &lt;code&gt;relist&lt;/code&gt;. Refer &lt;a href="https://github.com/openshift/origin/blob/release-3.11/vendor/k8s.io/kubernetes/pkg/kubelet/pleg/generic.go#L180-L284"&gt;here&lt;/a&gt; for full source codes.&lt;/p&gt; &lt;p&gt;Even though &lt;code&gt;relist&lt;/code&gt; is set as calling every 1s, it can take more than 1s to finish. If the container runtime responds slowly and/or when there are many container changes in one cycle. So, the next &lt;code&gt;relist&lt;/code&gt; will call after the previous one is complete. For example, if &lt;code&gt;relist&lt;/code&gt; takes 5s to complete, then next relist time is 6s (1s + 5s).&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-645987 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-start-relist.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-start-relist.png" alt="" width="681" height="371" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-start-relist.png 681w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-start-relist-300x163.png 300w" sizes="(max-width: 681px) 100vw, 681px" /&gt;&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/kubelet.go - NewMainKubelet() // Generic PLEG relies on relisting for discovering container events. // A longer period means that kubelet will take longer to detect container // changes and to update pod status. On the other hand, a shorter period // will cause more frequent relisting (e.g., container runtime operations), // leading to higher cpu usage. // Note that even though we set the period to 1s, the relisting itself can // take more than 1s to finish if the container runtime responds slowly // and/or when there are many container changes in one cycle. plegRelistPeriod = time.Second * 1 // NewMainKubelet instantiates a new Kubelet object along with all the required internal modules. // No initialization of Kubelet and its modules should happen here. func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration, ... : klet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{}) //// pkg/kubelet/pleg/generic.go - Start() // Start spawns a goroutine to relist periodically. func (g *GenericPLEG) Start() { go wait.Until(g.relist, g.relistPeriod, wait.NeverStop) } //// pkg/kubelet/pleg/generic.go - relist() func (g *GenericPLEG) relist() { ... WE WILL REVIEW HERE ... }&lt;/pre&gt; &lt;p&gt;The function process starts by recording some metrics for Kubelet (such as &lt;code&gt;kubelet_pleg_relist_latency_microseconds&lt;/code&gt;) and then takes all &amp;#8220;Pods&amp;#8221; (including stopped pods) list from the container runtime using the CRI interface for getting the current Pods status. This Pods list is used for comparison with previous pods list to check changes and the matched pod-level events are generated along with the changed states.&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - relist() : // get a current timestamp timestamp := g.clock.Now() // kubelet_pleg_relist_latency_microseconds for prometheus metrics defer func() { metrics.PLEGRelistLatency.Observe(metrics.SinceInMicroseconds(timestamp)) }() // Get all the pods. podList, err := g.runtime.GetPods(true) :&lt;/pre&gt; &lt;p&gt;The trace &amp;#8220;GetPods()&amp;#8221; call stack details are below.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-645997 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-getpods.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-getpods.png" alt="" width="709" height="561" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-getpods.png 709w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-getpods-300x237.png 300w" sizes="(max-width: 709px) 100vw, 709px" /&gt;&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/kuberuntime/kuberuntime_manager.go - GetPods() // GetPods returns a list of containers grouped by pods. The boolean parameter // specifies whether the runtime returns all containers including those already // exited and dead containers (used for garbage collection). func (m *kubeGenericRuntimeManager) GetPods(all bool) ([]*kubecontainer.Pod, error) { pods := make(map[kubetypes.UID]*kubecontainer.Pod) sandboxes, err := m.getKubeletSandboxes(all) : } //// pkg/kubelet/kuberuntime/kuberuntime_sandbox.go - getKubeletSandboxes() // getKubeletSandboxes lists all (or just the running) sandboxes managed by kubelet. func (m *kubeGenericRuntimeManager) getKubeletSandboxes(all bool) ([]*runtimeapi.PodSandbox, error) { : resp, err := m.runtimeService.ListPodSandbox(filter) : } //// pkg/kubelet/remote/remote_runtime.go - ListPodSandbox() // ListPodSandbox returns a list of PodSandboxes. func (r *RemoteRuntimeService) ListPodSandbox(filter *runtimeapi.PodSandboxFilter) ([]*runtimeapi.PodSandbox, error) { : resp, err := r.runtimeClient.ListPodSandbox(ctx, &amp;#38;runtimeapi.ListPodSandboxRequest{ : return resp.Items, nil }&lt;/pre&gt; &lt;p&gt;After getting all Pods, the last &lt;code&gt;relist&lt;/code&gt; time is updated as current timestamp. In other words, &lt;code&gt;Healthy()&lt;/code&gt; can be evaluated by using this updated timestamp.&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - relist() // update as a current timestamp g.updateRelistTime(timestamp)&lt;/pre&gt; &lt;p&gt;As mentioned previously, after comparing current and previous Pods list, every matched pod-level event is generated with the differences/changes between both lists below.&lt;/p&gt; &lt;p&gt;Here &lt;code&gt;generateEvents()&lt;/code&gt; generates matched pod-level events (such as &lt;code&gt;ContainerStarted&lt;/code&gt;, &lt;code&gt;ContainerDied&lt;/code&gt;, and so on), and then the events are updated by &lt;code&gt;updateEvents()&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - relist() pods := kubecontainer.Pods(podList) g.podRecords.setCurrent(pods) // Compare the old and the current pods, and generate events. eventsByPodID := map[types.UID][]*PodLifecycleEvent{} for pid := range g.podRecords { oldPod := g.podRecords.getOld(pid) pod := g.podRecords.getCurrent(pid) // Get all containers in the old and the new pod. allContainers := getContainersFromPods(oldPod, pod) for _, container := range allContainers { events := computeEvents(oldPod, pod, &amp;#38;container.ID) for _, e := range events { updateEvents(eventsByPodID, e) } } }&lt;/pre&gt; &lt;p&gt;The trace &lt;code&gt;computeEvents()&lt;/code&gt; call stack details are shown below.&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - computeEvents() func computeEvents(oldPod, newPod *kubecontainer.Pod, cid *kubecontainer.ContainerID) []*PodLifecycleEvent { : return generateEvents(pid, cid.ID, oldState, newState) } //// pkg/kubelet/pleg/generic.go - generateEvents() func generateEvents(podID types.UID, cid string, oldState, newState plegContainerState) []*PodLifecycleEvent { : glog.V(4).Infof("GenericPLEG: %v/%v: %v -&amp;#62; %v", podID, cid, oldState, newState) switch newState { case plegContainerRunning: return []*PodLifecycleEvent{{ID: podID, Type: ContainerStarted, Data: cid}} case plegContainerExited: return []*PodLifecycleEvent{{ID: podID, Type: ContainerDied, Data: cid}} case plegContainerUnknown: return []*PodLifecycleEvent{{ID: podID, Type: ContainerChanged, Data: cid}} case plegContainerNonExistent: switch oldState { case plegContainerExited: // We already reported that the container died before. return []*PodLifecycleEvent{{ID: podID, Type: ContainerRemoved, Data: cid}} default: return []*PodLifecycleEvent{{ID: podID, Type: ContainerDied, Data: cid}, {ID: podID, Type: ContainerRemoved, Data: cid}} } default: panic(fmt.Sprintf("unrecognized container state: %v", newState)) } }&lt;/pre&gt; &lt;p&gt;The last part of the process checks whether there are events associated with a pod, and updates the &lt;code&gt;podCache&lt;/code&gt; as follows.&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;/code&gt;&lt;code&gt;updateCache()&lt;/code&gt; will inspect each pod and update it one by one in a single loop, so if many pods changed during the same &lt;code&gt;relist&lt;/code&gt; period, this process can be a bottleneck. Lastly, updated new pod lifecycle events are sent to &lt;code&gt;eventChannel&lt;/code&gt; after updates.&lt;/p&gt; &lt;p&gt;Tracing call stack details are not as important for understanding the process, but some remote clients are called per pod for getting pod inspection information. This may increase latency for proportional to pod numbers, because many pods usually generate many events.&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - relist() // If there are events associated with a pod, we should update the // podCache. for pid, events := range eventsByPodID { pod := g.podRecords.getCurrent(pid) if g.cacheEnabled() { // updateCache() will inspect the pod and update the cache. If an // error occurs during the inspection, we want PLEG to retry again // in the next relist. To achieve this, we do not update the // associated podRecord of the pod, so that the change will be // detect again in the next relist. // TODO: If many pods changed during the same relist period, // inspecting the pod and getting the PodStatus to update the cache // serially may take a while. We should be aware of this and // parallelize if needed. if err := g.updateCache(pod, pid); err != nil { glog.Errorf("PLEG: Ignoring events for pod %s/%s: %v", pod.Name, pod.Namespace, err) : } : } // Update the internal storage and send out the events. g.podRecords.update(pid) for i := range events { // Filter out events that are not reliable and no other components use yet. if events[i].Type == ContainerChanged { continue } g.eventChannel &amp;#60;- events[i] } }&lt;/pre&gt; &lt;p&gt;The trace &lt;code&gt;updateCache()&lt;/code&gt; call stack details are below. Multiple remote requests are called by &lt;code&gt;GetPodStatus()&lt;/code&gt; for pod inspection.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-646007 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-updatecache.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-updatecache.png" alt="" width="709" height="711" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-updatecache.png 709w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-updatecache-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-updatecache-300x300.png 300w" sizes="(max-width: 709px) 100vw, 709px" /&gt;&lt;/p&gt; &lt;pre&gt;//// pkg/kubelet/pleg/generic.go - updateCache() func (g *GenericPLEG) updateCache(pod *kubecontainer.Pod, pid types.UID) error { : timestamp := g.clock.Now() // TODO: Consider adding a new runtime method // GetPodStatus(pod *kubecontainer.Pod) so that Docker can avoid listing // all containers again. status, err := g.runtime.GetPodStatus(pod.ID, pod.Name, pod.Namespace) : g.cache.Set(pod.ID, status, err, timestamp) return err } //// pkg/kubelet/kuberuntime/kuberuntime_manager.go - GetPodStatus() // GetPodStatus retrieves the status of the pod, including the // information of all containers in the pod that are visible in Runtime. func (m *kubeGenericRuntimeManager) GetPodStatus(uid kubetypes.UID, name, namespace string) (*kubecontainer.PodStatus, error) { podSandboxIDs, err := m.getSandboxIDByPodUID(uid, nil) : for idx, podSandboxID := range podSandboxIDs { podSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID) : } // Get statuses of all containers visible in the pod. containerStatuses, err := m.getPodContainerStatuses(uid, name, namespace) : } //// pkg/kubelet/kuberuntime/kuberuntime_sandbox.go - getSandboxIDByPodUID() // getPodSandboxID gets the sandbox id by podUID and returns ([]sandboxID, error). // Param state could be nil in order to get all sandboxes belonging to same pod. func (m *kubeGenericRuntimeManager) getSandboxIDByPodUID(podUID kubetypes.UID, state *runtimeapi.PodSandboxState) ([]string, error) { : sandboxes, err := m.runtimeService.ListPodSandbox(filter) : return sandboxIDs, nil } //// pkg/kubelet/remote/remote_runtime.go - PodSandboxStatus() // PodSandboxStatus returns the status of the PodSandbox. func (r *RemoteRuntimeService) PodSandboxStatus(podSandBoxID string) (*runtimeapi.PodSandboxStatus, error) { ctx, cancel := getContextWithTimeout(r.timeout) defer cancel() resp, err := r.runtimeClient.PodSandboxStatus(ctx, &amp;#38;runtimeapi.PodSandboxStatusRequest{ PodSandboxId: podSandBoxID, }) : return resp.Status, nil } //// pkg/kubelet/kuberuntime/kuberuntime_container.go - getPodContainerStatuses() // getPodContainerStatuses gets all containers' statuses for the pod. func (m *kubeGenericRuntimeManager) getPodContainerStatuses(uid kubetypes.UID, name, namespace string) ([]*kubecontainer.ContainerStatus, error) { // Select all containers of the given pod. containers, err := m.runtimeService.ListContainers(&amp;#38;runtimeapi.ContainerFilter{ LabelSelector: map[string]string{types.KubernetesPodUIDLabel: string(uid)}, }) : // TODO: optimization: set maximum number of containers per container name to examine. for i, c := range containers { status, err := m.runtimeService.ContainerStatus(c.Id) : } : return statuses, nil }&lt;/pre&gt; &lt;p&gt;We have taken a look at the &lt;code&gt;relist&lt;/code&gt; process through related source code and called stack trace. I hope this gives you more details about PLEG and how to update the required data in the process.&lt;/p&gt; &lt;h2&gt;Monitoring &amp;#8220;relist&amp;#8221;&lt;/h2&gt; &lt;p&gt;We can monitor the &lt;code&gt;relist&lt;/code&gt; latency using kubelet metrics. The &lt;code&gt;relist&lt;/code&gt; period is 1 second, in other words relist complete time (kubelet_pleg_relist_latency_microseconds) + 1 second is &lt;code&gt;kubelet_pleg_relist_interval_microseconds&lt;/code&gt;. Additionally, you can monitor how long each operation will take in container runtime. These metrics are also helpful to troubleshoot.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-646097 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table-1024x621.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table.png" alt="" width="1735" height="1053" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table.png 1735w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table-768x466.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-kubelet-metrics-table-1024x621.png 1024w" sizes="(max-width: 1735px) 100vw, 1735px" /&gt;&lt;/p&gt; &lt;p&gt;You can take the metrics using &lt;code&gt;https://127.0.0.1:10250/metrics&lt;/code&gt; on the node host.&lt;/p&gt; &lt;pre&gt;# HELP kubelet_pleg_relist_interval_microseconds Interval in microseconds between relisting in PLEG. # TYPE kubelet_pleg_relist_interval_microseconds summary kubelet_pleg_relist_interval_microseconds{quantile="0.5"} 1.054052e+06 kubelet_pleg_relist_interval_microseconds{quantile="0.9"} 1.074873e+06 kubelet_pleg_relist_interval_microseconds{quantile="0.99"} 1.126039e+06 kubelet_pleg_relist_interval_microseconds_count 5146 # HELP kubelet_pleg_relist_latency_microseconds Latency in microseconds for relisting pods in PLEG. # TYPE kubelet_pleg_relist_latency_microseconds summary kubelet_pleg_relist_latency_microseconds{quantile="0.5"} 53438 kubelet_pleg_relist_latency_microseconds{quantile="0.9"} 74396 kubelet_pleg_relist_latency_microseconds{quantile="0.99"} 115232 kubelet_pleg_relist_latency_microseconds_count 5106 # HELP kubelet_runtime_operations Cumulative number of runtime operations by operation type. # TYPE kubelet_runtime_operations counter kubelet_runtime_operations{operation_type="container_status"} 472 kubelet_runtime_operations{operation_type="create_container"} 93 kubelet_runtime_operations{operation_type="exec"} 1 kubelet_runtime_operations{operation_type="exec_sync"} 533 kubelet_runtime_operations{operation_type="image_status"} 579 kubelet_runtime_operations{operation_type="list_containers"} 10249 kubelet_runtime_operations{operation_type="list_images"} 782 kubelet_runtime_operations{operation_type="list_podsandbox"} 10154 kubelet_runtime_operations{operation_type="podsandbox_status"} 315 kubelet_runtime_operations{operation_type="pull_image"} 57 kubelet_runtime_operations{operation_type="remove_container"} 49 kubelet_runtime_operations{operation_type="run_podsandbox"} 28 kubelet_runtime_operations{operation_type="start_container"} 93 kubelet_runtime_operations{operation_type="status"} 1116 kubelet_runtime_operations{operation_type="stop_container"} 9 kubelet_runtime_operations{operation_type="stop_podsandbox"} 33 kubelet_runtime_operations{operation_type="version"} 564 # HELP kubelet_runtime_operations_latency_microseconds Latency in microseconds of runtime operations. Broken down by operation type. # TYPE kubelet_runtime_operations_latency_microseconds summary kubelet_runtime_operations_latency_microseconds{operation_type="container_status",quantile="0.5"} 12117 kubelet_runtime_operations_latency_microseconds{operation_type="container_status",quantile="0.9"} 26607 kubelet_runtime_operations_latency_microseconds{operation_type="container_status",quantile="0.99"} 27598 kubelet_runtime_operations_latency_microseconds_count{operation_type="container_status"} 486 kubelet_runtime_operations_latency_microseconds{operation_type="list_containers",quantile="0.5"} 29972 kubelet_runtime_operations_latency_microseconds{operation_type="list_containers",quantile="0.9"} 47907 kubelet_runtime_operations_latency_microseconds{operation_type="list_containers",quantile="0.99"} 80982 kubelet_runtime_operations_latency_microseconds_count{operation_type="list_containers"} 10812 kubelet_runtime_operations_latency_microseconds{operation_type="list_podsandbox",quantile="0.5"} 18053 kubelet_runtime_operations_latency_microseconds{operation_type="list_podsandbox",quantile="0.9"} 28116 kubelet_runtime_operations_latency_microseconds{operation_type="list_podsandbox",quantile="0.99"} 68748 kubelet_runtime_operations_latency_microseconds_count{operation_type="list_podsandbox"} 10712 kubelet_runtime_operations_latency_microseconds{operation_type="podsandbox_status",quantile="0.5"} 4918 kubelet_runtime_operations_latency_microseconds{operation_type="podsandbox_status",quantile="0.9"} 15671 kubelet_runtime_operations_latency_microseconds{operation_type="podsandbox_status",quantile="0.99"} 18398 kubelet_runtime_operations_latency_microseconds_count{operation_type="podsandbox_status"} 323 :&lt;/pre&gt; &lt;p&gt;The above metrics can monitor using Prometheus by default on Red Hat OpenShift.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-full wp-image-646017 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics-1024x483.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics.png" alt="" width="2037" height="961" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics.png 2037w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics-768x362.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/pleg-prometheus-metrics-1024x483.png 1024w" sizes="(max-width: 2037px) 100vw, 2037px" /&gt;&lt;/p&gt; &lt;h2&gt;Conclusions&lt;/h2&gt; &lt;p&gt;In my experience, &amp;#8220;PLEG is not healthy&amp;#8221; can happen due to various causes, and I believe there are many potential causes we have not run into yet. I&amp;#8217;d like to introduce the following causes for your additional information.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Container runtime latency or timeout (performance degradation, deadlock, bugs&amp;#8230;) during remote requests.&lt;/li&gt; &lt;li&gt;Too many running pods for host resources or too many running pods on high-spec hosts to complete the relist within 3 min. As seen in this article, events and latency are proportional to the pod numbers regardless of host resources.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/kubernetes/kubernetes/issues/72482"&gt;Deadlock in PLEG relist&lt;/a&gt; has been fixed as of Kubernetes 1.14 (OpenShift 4.2).&lt;/li&gt; &lt;li&gt;CNI bugs when getting a pod network status.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;References&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md"&gt;Kubelet: Pod Lifecycle Event Generator (PLEG)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/runtime-pod-cache.md"&gt;Kubelet: Runtime Pod Cache&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/openshift/origin/blob/release-3.11/vendor/k8s.io/kubernetes/pkg/kubelet/pleg/generic.go#L180-L284"&gt;relist() in kubernetes/pkg/kubelet/pleg/generic.go&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Past bug about CNI — &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1486914#c16"&gt;PLEG is not healthy error, node marked NotReady&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#38;linkname=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F13%2Fpod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes%2F&amp;#038;title=Pod%20Lifecycle%20Event%20Generator%3A%20Understanding%20the%20%E2%80%9CPLEG%20is%20not%20healthy%E2%80%9D%20issue%20in%20Kubernetes" data-a2a-url="https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/" data-a2a-title="Pod Lifecycle Event Generator: Understanding the “PLEG is not healthy” issue in Kubernetes"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/"&gt;Pod Lifecycle Event Generator: Understanding the &amp;#8220;PLEG is not healthy&amp;#8221; issue in Kubernetes&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/k5tVaV2KsXc" height="1" width="1" alt=""/&gt;</content><summary>In this article, I’ll explore the “PLEG is not healthy” issue in Kubernetes, which sometimes leads to a “NodeNotReady” status. When understanding how the Pod Lifecycle Event Generator (PLEG) works, it is helpful to also understand troubleshooting around this issue. What is PLEG? The PLEG module in kubelet (Kubernetes) adjusts the container runtime state with each matched pod-level event and keeps ...</summary><dc:creator>Daein Park</dc:creator><dc:date>2019-11-13T08:00:25Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/</feedburner:origLink></entry><entry><title>Plumbing Kubernetes CI/CD with Tekton</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/oRwtfcN3pNI/" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="DevNation Live" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Tekton" scheme="searchisko:content:tags" /><author><name>Editorial Team</name></author><id>searchisko:content:id:jbossorg_blog-plumbing_kubernetes_ci_cd_with_tekton</id><updated>2019-11-12T08:00:31Z</updated><published>2019-11-12T08:00:31Z</published><content type="html">&lt;p&gt;Our first &lt;a href="https://developers.redhat.com/devnationlive-india/"&gt;DevNation Live regional event was held in Bengaluru, India&lt;/a&gt; in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists.&lt;/p&gt; &lt;p&gt;In this session, &lt;a href="https://developers.redhat.com/blog/author/kameshsampath/"&gt;Kamesh Sampath&lt;/a&gt; introduces &lt;a href="https://developers.redhat.com/blog/2019/07/19/getting-started-with-tekton-on-red-hat-openshift/"&gt;Tekton&lt;/a&gt;, which is the &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;-native way of defining and running &lt;a href="https://developers.redhat.com/blog/2019/07/22/how-to-build-cloud-native-ci-cd-pipelines-with-tekton-on-kubernetes/"&gt;CI/CD&lt;/a&gt;. Sampath explores the characteristics of Tekton—cloud-native, decoupled, and declarative—and shows how to combine various building blocks of Tekton to build and deploy a cloud-native application.&lt;span id="more-624737"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Watch the complete presentation:&lt;br /&gt; &lt;iframe src="https://www.youtube.com/embed/5zwW6DHCWFc" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;Learn more&lt;/h3&gt; &lt;p&gt;Join us at an upcoming&lt;a href="https://developers.redhat.com/events/"&gt; developer event&lt;/a&gt;, and see our collection of&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt; past DevNation Live tech talks&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To hear more from Red Hat experts, &lt;a href="https://redhat-events.com/devnation_austin2019/?sc_cid=7013a000002D5uHAAS" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://redhat-events.com/devnation_austin2019/?sc_cid%3D7013a000002D5uHAAS&amp;#38;source=gmail&amp;#38;ust=1572807311274000&amp;#38;usg=AFQjCNHByfT8tiI-TLiXXHEc42cSc9c0HQ"&gt;join us in Austin on December 12, 2019&lt;/a&gt; for a free, one-day, two-track DevNation Live event and get hands-on experience with Kubernetes, Quarkus, and more. &lt;strong&gt;&lt;a href="https://redhat-events.com/devnation_austin2019/?sc_cid=7013a000002D5uHAAS" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://redhat-events.com/devnation_austin2019/?sc_cid%3D7013a000002D5uHAAS&amp;#38;source=gmail&amp;#38;ust=1572807311274000&amp;#38;usg=AFQjCNHByfT8tiI-TLiXXHEc42cSc9c0HQ"&gt;Register now&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#38;linkname=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fplumbing-kubernetes-ci-cd-with-tekton%2F&amp;#038;title=Plumbing%20Kubernetes%20CI%2FCD%20with%20Tekton" data-a2a-url="https://developers.redhat.com/blog/2019/11/12/plumbing-kubernetes-ci-cd-with-tekton/" data-a2a-title="Plumbing Kubernetes CI/CD with Tekton"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/12/plumbing-kubernetes-ci-cd-with-tekton/"&gt;Plumbing Kubernetes CI/CD with Tekton&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/oRwtfcN3pNI" height="1" width="1" alt=""/&gt;</content><summary>Our first DevNation Live regional event was held in Bengaluru, India in July. This free technology event focused on open source innovations, with sessions presented by elite Red Hat technologists. In this session, Kamesh Sampath introduces Tekton, which is the Kubernetes-native way of defining and running CI/CD. Sampath explores the characteristics of Tekton—cloud-native, decoupled, and declarativ...</summary><dc:creator>Editorial Team</dc:creator><dc:date>2019-11-12T08:00:31Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/12/plumbing-kubernetes-ci-cd-with-tekton/</feedburner:origLink></entry><entry><title>Using the Red Hat OpenShift tuned Operator for Elasticsearch</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Hjf_SUgMV70/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Storafe" scheme="searchisko:content:tags" /><author><name>Rarm Nagalingam</name></author><id>searchisko:content:id:jbossorg_blog-using_the_red_hat_openshift_tuned_operator_for_elasticsearch</id><updated>2019-11-12T08:00:10Z</updated><published>2019-11-12T08:00:10Z</published><content type="html">&lt;p&gt;I recently assisted a client to deploy Elastic Cloud on Kubernetes (ECK) on &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift 4.x&lt;/a&gt;. They had run into an issue where Elasticsearch would throw an error similar to:&lt;/p&gt; &lt;pre&gt;Max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]&lt;/pre&gt; &lt;p&gt;According to the official documentation, &lt;a href="https://www.elastic.co/guide/en/cloud-on-k8s/current/index.html"&gt;Elasticsearch&lt;/a&gt; uses a &lt;code&gt;mmapfs&lt;/code&gt; directory by default to store its indices. The default operating system limits on mmap counts are likely to be too low, which may result in out of memory exceptions. Usually, administrators would just increase the limits by running:&lt;/p&gt; &lt;pre&gt;sysctl -w vm.max_map_count=262144&lt;/pre&gt; &lt;p&gt;However, OpenShift uses &lt;a href="https://www.openshift.com/learn/coreos/"&gt;Red Hat CoreOS&lt;/a&gt; for its worker nodes and, because it is an automatically updating, minimal operating system for running containerized workloads, you shouldn&amp;#8217;t manually log on to worker nodes and make changes. This approach is unscalable and results in a worker node becoming tainted. Instead, OpenShift provides an elegant and scalable method to achieve the same via its &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/nodes/nodes-node-tuning-operator.html"&gt;Node Tuning Operator&lt;/a&gt;.&lt;span id="more-645287"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;The default tuned configuration contains a profile for Elasticsearch. The tuned operator on a given node looks for a pod running on the same node with the tuned.openshift.io/elasticsearch label set (match). If found, it applies the &lt;code&gt;sysctl&lt;/code&gt; command (data).&lt;/p&gt; &lt;p&gt;You can view the default configuration by logging into your OpenShift cluster and running:&lt;/p&gt; &lt;pre&gt;bastion $ oc get Tuned/default -o yaml -n openshift-cluster-node-tuning-operator apiVersion: tuned.openshift.io/v1alpha1 kind: Tuned metadata: name: default namespace: openshift-cluster-node-tuning-operator spec: profile: ... ... - name: "openshift-node-es" data: | [main] summary=Optimize systems running ES on OpenShift nodes include=openshift-node [sysctl] vm.max_map_count=262144 recommend: ... ... - profile: "openshift-node-es" priority: 20 match: - label: "tuned.openshift.io/elasticsearch" type: "pod" ``` &lt;/pre&gt; &lt;p&gt;The trick is to ensure that the Elasticsearch operator tags its pods with the label: &lt;code&gt;tuned.openshift.io/elasticsearch&lt;/code&gt;. Below is an example of how to achieve this.&lt;/p&gt; &lt;pre&gt;--- apiVersion: elasticsearch.k8s.elastic.co/v1alpha1 kind: Elasticsearch metadata: name: elasticsearch-tst spec: version: "7.2.0" setVmMaxMapCount: false nodes: - config: node.master: true node.data: true nodeCount: 1 podTemplate: metadata: labels: tuned.openshift.io/elasticsearch: "" &lt;/pre&gt; &lt;p&gt;The tuned operator will read the pod label &lt;code&gt;tuned.openshift.io/elasticsearch&lt;/code&gt; and add the &lt;code&gt;vm.max_map_count=262144&lt;/code&gt; to the node running the pod. This is useful because pods can be terminated and scheduled on different nodes across the cluster. No more manually worrying about the sysctl configuration of the nodes running a particular workload.&lt;/p&gt; &lt;p&gt;Thanks to James Ryles for helping solve this problem.&lt;/p&gt; &lt;p&gt;Let me know if you run into any issues.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#38;linkname=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F11%2F12%2Fusing-the-red-hat-openshift-tuned-operator-for-elasticsearch%2F&amp;#038;title=Using%20the%20Red%20Hat%20OpenShift%20tuned%20Operator%20for%20Elasticsearch" data-a2a-url="https://developers.redhat.com/blog/2019/11/12/using-the-red-hat-openshift-tuned-operator-for-elasticsearch/" data-a2a-title="Using the Red Hat OpenShift tuned Operator for Elasticsearch"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/11/12/using-the-red-hat-openshift-tuned-operator-for-elasticsearch/"&gt;Using the Red Hat OpenShift tuned Operator for Elasticsearch&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Hjf_SUgMV70" height="1" width="1" alt=""/&gt;</content><summary>I recently assisted a client to deploy Elastic Cloud on Kubernetes (ECK) on Red Hat OpenShift 4.x. They had run into an issue where Elasticsearch would throw an error similar to: Max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] According to the official documentation, Elasticsearch uses a mmapfs directory by default to store its indices. The default o...</summary><dc:creator>Rarm Nagalingam</dc:creator><dc:date>2019-11-12T08:00:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/11/12/using-the-red-hat-openshift-tuned-operator-for-elasticsearch/</feedburner:origLink></entry></feed>
